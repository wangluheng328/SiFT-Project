{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwitterUCI_Deberta_SiFT_0%.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jJKaoairpdRa",
        "EFSJzwI5pujc",
        "hmSpMRD5qaqE",
        "bunW4qF4qSyZ"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "28b31ea321a74f1690ba8225151e95d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_56a92169620f41e7823988b2a66511ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6adb8015d61f4178b6b2cf67dbda898d",
              "IPY_MODEL_938c8b7f8c9c45bc991b10e9dbf0c924"
            ]
          }
        },
        "56a92169620f41e7823988b2a66511ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6adb8015d61f4178b6b2cf67dbda898d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_815cad626252454aae49c4be01ab39d3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898825,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898825,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8526e3ec8cdc4898aae3cc7a5fd958b4"
          }
        },
        "938c8b7f8c9c45bc991b10e9dbf0c924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01569e01e3ec4af3b958735d1f4201f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 1.08MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90f4a6344ed7473f9e91768612b8575d"
          }
        },
        "815cad626252454aae49c4be01ab39d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8526e3ec8cdc4898aae3cc7a5fd958b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01569e01e3ec4af3b958735d1f4201f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90f4a6344ed7473f9e91768612b8575d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "402fe581689e467086c8dd3bee7dad32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d3c6aa4c5a64d79a2ecc2c8855027e4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac41dbe42905465dafc3d11ac943d133",
              "IPY_MODEL_9a6ff155e6414b3b8ed835c28e9b9df1"
            ]
          }
        },
        "4d3c6aa4c5a64d79a2ecc2c8855027e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac41dbe42905465dafc3d11ac943d133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57b9875d39154bf29118fb2eadedb88c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0519393216fb4d34bbb2b194db5b4da5"
          }
        },
        "9a6ff155e6414b3b8ed835c28e9b9df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d5c625f5009433db5060b56e0e91d29",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.14MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61af5d5584504c829a1c8b175409e953"
          }
        },
        "57b9875d39154bf29118fb2eadedb88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0519393216fb4d34bbb2b194db5b4da5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d5c625f5009433db5060b56e0e91d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61af5d5584504c829a1c8b175409e953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58c1fd40b6ce4a86b4a5dc74f542bf79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_21fdb63afe3b41358508c8c7fd03d1cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f93d704ac0cd42ffb975653d9c2f9656",
              "IPY_MODEL_1128c2f2f9234520aeb74cd14ab5bc58"
            ]
          }
        },
        "21fdb63afe3b41358508c8c7fd03d1cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f93d704ac0cd42ffb975653d9c2f9656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e02dc28b6fa64a939d2c8667624b5873",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 52,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 52,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5815064b2d94a5397108efa59d7731e"
          }
        },
        "1128c2f2f9234520aeb74cd14ab5bc58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c6fe600db624a7f89dafe8e53843032",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 52.0/52.0 [00:00&lt;00:00, 328B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2f0667b59c144c1955ebaf5c5030f5e"
          }
        },
        "e02dc28b6fa64a939d2c8667624b5873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5815064b2d94a5397108efa59d7731e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c6fe600db624a7f89dafe8e53843032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2f0667b59c144c1955ebaf5c5030f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5293623be2874771937f8ee82359c5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_73f1410c5ed4453789499edde80b98e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b90a66f60cbb4ff99160753c3815ac67",
              "IPY_MODEL_b8ea16473a0a4a9ea391f97f30b3cbc8"
            ]
          }
        },
        "73f1410c5ed4453789499edde80b98e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b90a66f60cbb4ff99160753c3815ac67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95574dbdd5d74029917eb20012cc47ee",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 474,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 474,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d86fbabcfae47a096ccc990f874d248"
          }
        },
        "b8ea16473a0a4a9ea391f97f30b3cbc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69ee0273a95341db889b6a6b5ed4fec8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 474/474 [00:00&lt;00:00, 1.57kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf63f65aef6d494fb9d7a08077e5758c"
          }
        },
        "95574dbdd5d74029917eb20012cc47ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d86fbabcfae47a096ccc990f874d248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69ee0273a95341db889b6a6b5ed4fec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf63f65aef6d494fb9d7a08077e5758c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75126727425c4de58862cf15b7a72c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_20fd6178535f4514bfadf2df0165b83f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_670b7e2e655a4f79a37937d533290e7b",
              "IPY_MODEL_e847fb1754c1472da301a9710d3374da"
            ]
          }
        },
        "20fd6178535f4514bfadf2df0165b83f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "670b7e2e655a4f79a37937d533290e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7eb7f1a409f14aa2a5291ba0dfcc3cac",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 558582766,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 558582766,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e6b2c1b429f4aadb815c2cf81fd33f0"
          }
        },
        "e847fb1754c1472da301a9710d3374da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cea2eae51f934ba6b1ff890ba73331a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 559M/559M [00:14&lt;00:00, 37.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26ed7145ae4749ff94b29caf55b6067f"
          }
        },
        "7eb7f1a409f14aa2a5291ba0dfcc3cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e6b2c1b429f4aadb815c2cf81fd33f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cea2eae51f934ba6b1ff890ba73331a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26ed7145ae4749ff94b29caf55b6067f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# DeBERTa Fine-Tuning on CoLA with SMART and SiFT\n",
        "\n",
        "This notebook was orginally created by Chris McCormick and Nick Ryan. We made changes for SiFT and SMART, as well as our custom BERT/DeBERTa class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJKaoairpdRa"
      },
      "source": [
        "##Data and Importing Modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5186561a-ba01-482e-e404-8be2ba1a0c28"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171f9e61-fdef-40f6-84d4-6c2152c7cef8"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "953e78ce-4eaa-4dae-9aa8-9e16daf82bcc"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 26.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31492648-64a1-4627-f1eb-ae7a09978079"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=5f18afc8e56e53e45c46eb6ffe3daf9461c86078e276cf9d626521b6080ccdf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "FBXpjYJ0iHcp",
        "outputId": "d936c971-697a-45cd-a42b-83c13f6467a1"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/fourth.csv\"\n",
        "download = requests.get(url).content\n",
        "df = pd.read_csv(io.StringIO(download.decode('utf-8')),index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label                                              tweet\n",
              "id                                                          \n",
              "1       0   @user when a father is dysfunctional and is s...\n",
              "2       0  @user @user thanks for #lyft credit i can't us...\n",
              "3       0                                bihday your majesty\n",
              "4       0  #model   i love u take with u all the time in ...\n",
              "5       0             factsguide: society now    #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5K7JlQ-BPts"
      },
      "source": [
        "df1 = df[df['label']==1]\n",
        "df0 = df[df['label']==0]\n",
        "df0 = df0[:2200]\n",
        "df_ori = pd.concat([df0, df1], axis = 0, join = 'inner')\n",
        "df_ori = df_ori.sample(frac = 1).reset_index(drop = True)\n",
        "df = df_ori[:2000]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "MvfL3MLjBsqb",
        "outputId": "1140eaa9-b610-4fef-ddb3-b25a4ce9bf64"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>(; every time i am   this electro #strobe make...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>a victim cant victimise the oppressor... we ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>#allahsoil âwe the peopleâ originally mean...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when is this coming to singapore!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>omg, hope you had fun seeing selena gomez live...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                              tweet\n",
              "0      0  (; every time i am   this electro #strobe make...\n",
              "1      1  a victim cant victimise the oppressor... we ha...\n",
              "2      1  #allahsoil âwe the peopleâ originally mean...\n",
              "3      0          @user when is this coming to singapore!  \n",
              "4      0  omg, hope you had fun seeing selena gomez live..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOPpgw4Gi6hc"
      },
      "source": [
        "sentences = df.tweet.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RAaRTCcDCOA",
        "outputId": "675b16ad-fbc2-4dff-9f8b-dd033d20db3d"
      },
      "source": [
        "labels.sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFSJzwI5pujc"
      },
      "source": [
        "## Tokenization and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "28b31ea321a74f1690ba8225151e95d2",
            "56a92169620f41e7823988b2a66511ae",
            "6adb8015d61f4178b6b2cf67dbda898d",
            "938c8b7f8c9c45bc991b10e9dbf0c924",
            "815cad626252454aae49c4be01ab39d3",
            "8526e3ec8cdc4898aae3cc7a5fd958b4",
            "01569e01e3ec4af3b958735d1f4201f6",
            "90f4a6344ed7473f9e91768612b8575d",
            "402fe581689e467086c8dd3bee7dad32",
            "4d3c6aa4c5a64d79a2ecc2c8855027e4",
            "ac41dbe42905465dafc3d11ac943d133",
            "9a6ff155e6414b3b8ed835c28e9b9df1",
            "57b9875d39154bf29118fb2eadedb88c",
            "0519393216fb4d34bbb2b194db5b4da5",
            "3d5c625f5009433db5060b56e0e91d29",
            "61af5d5584504c829a1c8b175409e953",
            "58c1fd40b6ce4a86b4a5dc74f542bf79",
            "21fdb63afe3b41358508c8c7fd03d1cd",
            "f93d704ac0cd42ffb975653d9c2f9656",
            "1128c2f2f9234520aeb74cd14ab5bc58",
            "e02dc28b6fa64a939d2c8667624b5873",
            "d5815064b2d94a5397108efa59d7731e",
            "5c6fe600db624a7f89dafe8e53843032",
            "a2f0667b59c144c1955ebaf5c5030f5e"
          ]
        },
        "outputId": "f440bbb7-2000-45b8-c911-e5bd4a8a35c2"
      },
      "source": [
        "from transformers import DebertaTokenizer\n",
        "print('Loading DeBERTa tokenizer...')\n",
        "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading DeBERTa tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28b31ea321a74f1690ba8225151e95d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898825.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "402fe581689e467086c8dd3bee7dad32",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58c1fd40b6ce4a86b4a5dc74f542bf79",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=52.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c96d77b5-830a-44b2-e9d7-b6b24c05e812"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  (; every time i am   this electro #strobe makes me #happy believe. thanks you for exits. i cant without all you. ;)\n",
            "Tokenized:  ['(', ';', 'Ġevery', 'Ġtime', 'Ġi', 'Ġam', 'Ġ', 'Ġ', 'Ġthis', 'Ġelectro', 'Ġ#', 'stro', 'be', 'Ġmakes', 'Ġme', 'Ġ#', 'happy', 'Ġbelieve', '.', 'Ġthanks', 'Ġyou', 'Ġfor', 'Ġexits', '.', 'Ġi', 'Ġcant', 'Ġwithout', 'Ġall', 'Ġyou', '.', 'Ġ;)']\n",
            "Token IDs:  [1640, 131, 358, 86, 939, 524, 1437, 1437, 42, 29541, 849, 26764, 1610, 817, 162, 849, 27333, 679, 4, 2446, 47, 13, 21855, 4, 939, 17672, 396, 70, 47, 4, 48306]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15ad564-3eb9-4f59-92dd-a6fccf54c41e"
      },
      "source": [
        "max_len = 0\n",
        "for sent in sentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f7e27d2-845f-414b-9c65-1d8e795d17a2"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  (; every time i am   this electro #strobe makes me #happy believe. thanks you for exits. i cant without all you. ;)\n",
            "Token IDs: tensor([    1,  1640,   131,   358,    86,   939,   524,  1437,  1437,    42,\n",
            "        29541,   849, 26764,  1610,   817,   162,   849, 27333,   679,     4,\n",
            "         2446,    47,    13, 21855,     4,   939, 17672,   396,    70,    47,\n",
            "            4, 48306,     2,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a3988f-0066-4e3d-ac75-7d7f1a4cc7cc"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,800 training samples\n",
            "  200 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73S4P4SMp6hX"
      },
      "source": [
        "## Custom Deberta Class and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOteWAT-Adqx"
      },
      "source": [
        "from transformers import DebertaForSequenceClassification, AdamW, DebertaConfig, DebertaPreTrainedModel, DebertaModel\n",
        "from transformers.models.deberta.modeling_deberta import *\n",
        "#from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "class CustomDebertaForClassification(DebertaForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        #self.bert = BertForSequenceClassification(config).from_pretrained(\"bert-base-uncased\",num_labels = 2,output_attentions = False, output_hidden_states = False)\n",
        "        self.embeddings = self.deberta.embeddings\n",
        "        self.encoder = self.deberta.encoder\n",
        "        self.z_steps = 0 #copied from DebertaModel source code\n",
        "\n",
        "\n",
        "    def embed(self, input_ids=None, \n",
        "                    mask=None,\n",
        "                    token_type_ids=None, \n",
        "                    position_ids=None, \n",
        "                    inputs_embeds=None\n",
        "                    ):\n",
        "        # See: BERTModel.forward\n",
        "        return self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            mask=mask,\n",
        "            inputs_embeds=inputs_embeds\n",
        "        )\n",
        "    \n",
        "    def predict(self,embedding_output,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_extended_attention_mask=None,\n",
        "                past_key_values=None,\n",
        "                use_cache=None,\n",
        "                output_attentions=None,\n",
        "                output_hidden_states=None,\n",
        "                return_dict=True): \n",
        "        encoder_outputs = self.encoder(\n",
        "                                        embedding_output,\n",
        "                                        attention_mask,\n",
        "                                        output_hidden_states=True,\n",
        "                                        output_attentions=output_attentions,\n",
        "                                        return_dict=return_dict\n",
        "        )\n",
        "        encoded_layers = encoder_outputs[1]\n",
        "\n",
        "        if self.z_steps > 1:\n",
        "            hidden_states = encoded_layers[-2]\n",
        "            layers = [self.encoder.layer[-1] for _ in range(self.z_steps)]\n",
        "            query_states = encoded_layers[-1]\n",
        "            rel_embeddings = self.encoder.get_rel_embedding()\n",
        "            attention_mask = self.encoder.get_attention_mask(attention_mask)\n",
        "            rel_pos = self.encoder.get_rel_pos(embedding_output)\n",
        "            for layer in layers[1:]:\n",
        "                query_states = layer(\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    return_att=False,\n",
        "                    query_states=query_states,\n",
        "                    relative_pos=rel_pos,\n",
        "                    rel_embeddings=rel_embeddings,\n",
        "                )\n",
        "                encoded_layers.append(query_states)\n",
        "\n",
        "        sequence_output = encoded_layers[-1]\n",
        "\n",
        "        # if not return_dict:\n",
        "        #     return (sequence_output,) + encoder_outputs[(1 if output_hidden_states else 2) :]\n",
        "\n",
        "        outputs = BaseModelOutput(\n",
        "            last_hidden_state=sequence_output,\n",
        "            hidden_states=encoder_outputs.hidden_states if output_hidden_states else None,\n",
        "            attentions=encoder_outputs.attentions,\n",
        "        )\n",
        "\n",
        "        \n",
        "\n",
        "        pooled_output = self.pooler(outputs[0])\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        return logits\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5293623be2874771937f8ee82359c5dd",
            "73f1410c5ed4453789499edde80b98e8",
            "b90a66f60cbb4ff99160753c3815ac67",
            "b8ea16473a0a4a9ea391f97f30b3cbc8",
            "95574dbdd5d74029917eb20012cc47ee",
            "7d86fbabcfae47a096ccc990f874d248",
            "69ee0273a95341db889b6a6b5ed4fec8",
            "cf63f65aef6d494fb9d7a08077e5758c",
            "75126727425c4de58862cf15b7a72c11",
            "20fd6178535f4514bfadf2df0165b83f",
            "670b7e2e655a4f79a37937d533290e7b",
            "e847fb1754c1472da301a9710d3374da",
            "7eb7f1a409f14aa2a5291ba0dfcc3cac",
            "9e6b2c1b429f4aadb815c2cf81fd33f0",
            "cea2eae51f934ba6b1ff890ba73331a3",
            "26ed7145ae4749ff94b29caf55b6067f"
          ]
        },
        "id": "IdNBO5qk2-i_",
        "collapsed": true,
        "outputId": "76d975c3-d9b7-4d2e-c098-91ec2366ddee"
      },
      "source": [
        "#@title\n",
        "model = CustomDebertaForClassification.from_pretrained(\n",
        "    \"microsoft/deberta-base\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5293623be2874771937f8ee82359c5dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=474.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75126727425c4de58862cf15b7a72c11",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=558582766.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing CustomDebertaForClassification: ['config', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight']\n",
            "- This IS expected if you are initializing CustomDebertaForClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomDebertaForClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomDebertaForClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.self.pos_q_proj.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.self.pos_q_proj.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.7.attention.self.pos_proj.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.rel_embeddings.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.v_bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.pos_q_proj.weight', 'encoder.layer.6.attention.self.pos_q_proj.weight', 'encoder.layer.2.attention.self.pos_proj.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.attention.self.q_bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.8.attention.self.q_bias', 'encoder.layer.4.attention.self.pos_q_proj.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.1.attention.self.in_proj.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.pos_q_proj.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.attention.self.pos_proj.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.q_bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.1.attention.self.v_bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.in_proj.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.attention.self.in_proj.weight', 'classifier.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.attention.self.q_bias', 'pooler.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.7.attention.self.q_bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.2.attention.self.v_bias', 'encoder.layer.10.attention.self.q_bias', 'encoder.layer.8.attention.self.pos_proj.weight', 'encoder.layer.11.attention.self.v_bias', 'encoder.layer.6.attention.self.v_bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.self.q_bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.pos_proj.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'pooler.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.2.attention.self.q_bias', 'encoder.layer.7.attention.self.v_bias', 'encoder.layer.5.attention.self.v_bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.2.attention.self.pos_q_proj.weight', 'encoder.layer.3.attention.self.in_proj.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.self.v_bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.attention.self.q_bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.2.attention.self.in_proj.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.attention.self.pos_q_proj.weight', 'encoder.layer.1.attention.self.pos_q_proj.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.attention.self.pos_q_proj.bias', 'encoder.layer.0.attention.self.pos_q_proj.bias', 'encoder.layer.11.attention.self.pos_q_proj.weight', 'encoder.layer.4.attention.self.pos_proj.weight', 'encoder.layer.6.output.dense.bias', 'classifier.weight', 'encoder.layer.9.attention.self.in_proj.weight', 'encoder.layer.7.attention.self.in_proj.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.self.v_bias', 'embeddings.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.q_bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.pos_q_proj.weight', 'encoder.layer.0.attention.self.pos_proj.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.attention.self.pos_q_proj.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.attention.self.pos_q_proj.bias', 'encoder.layer.11.attention.self.pos_proj.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.attention.self.pos_q_proj.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.3.attention.self.v_bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.0.attention.self.pos_q_proj.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.v_bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.in_proj.weight', 'encoder.layer.6.attention.self.in_proj.weight', 'encoder.layer.2.attention.self.pos_q_proj.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.self.v_bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.self.pos_q_proj.weight', 'encoder.layer.7.attention.self.pos_q_proj.weight', 'encoder.layer.10.attention.self.pos_q_proj.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.5.attention.self.q_bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.q_bias', 'encoder.layer.4.attention.self.in_proj.weight', 'encoder.layer.5.attention.self.pos_proj.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.pos_q_proj.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.attention.self.in_proj.weight', 'encoder.layer.10.attention.self.pos_proj.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.attention.self.pos_proj.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.8.attention.self.in_proj.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.self.pos_q_proj.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.attention.self.pos_q_proj.weight', 'encoder.layer.9.attention.self.pos_proj.weight', 'encoder.layer.3.attention.output.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomDebertaForClassification(\n",
              "  (deberta): DebertaModel(\n",
              "    (embeddings): DebertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "      (LayerNorm): DebertaLayerNorm()\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (1): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (2): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (3): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (4): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (5): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (6): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (7): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (8): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (9): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (10): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (11): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(1024, 768)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): StableDropout()\n",
              "  (embeddings): DebertaEmbeddings(\n",
              "    (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "    (LayerNorm): DebertaLayerNorm()\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (encoder): DebertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (1): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (2): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (3): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (4): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (5): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (6): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (7): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (8): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (9): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (10): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (11): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (rel_embeddings): Embedding(1024, 768)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmSpMRD5qaqE"
      },
      "source": [
        "##Noise Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG5DszcpDAjw"
      },
      "source": [
        "from torch.nn import LayerNorm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def normalize_embed(embed):\n",
        "    embed_mean = torch.mean(embed,dim=(1,2))\n",
        "    embed_std = torch.std(embed, dim=(1,2))\n",
        "\n",
        "    embed_clone = torch.clone(embed)\n",
        "\n",
        "    for i in range(0,embed_clone.size()[0]):\n",
        "        # embed_clone[i] = torch.div(torch.sub(embed_clone[i],embed_mean[i]),embed_std[i])\n",
        "        embed_clone[i] = (embed_clone[i] - embed_mean[i]) / embed_std[i]\n",
        "    return embed_clone, embed_mean, embed_std\n",
        "\n",
        "def denormalize_embed(embed, embed_mean, embed_std):\n",
        "    for i in range(0,embed.size()[0]):\n",
        "        # embed[i] = (embed[i] - embed_mean[i]) / embed_std[i]\n",
        "        embed[i] = (embed[i] * embed_std[i]) + embed_mean[i]\n",
        "    return embed \n",
        "\n",
        "def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n",
        "    logit = logit.view(-1, logit.size(-1)).float()\n",
        "    target = target.view(-1, target.size(-1)).float()\n",
        "    bs = logit.size(0)\n",
        "    p = F.log_softmax(logit, 1).exp()\n",
        "    y = F.log_softmax(target, 1).exp()\n",
        "    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n",
        "    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n",
        "    if reduce:\n",
        "        return (p* (rp- ry) * 2).sum() / bs\n",
        "    else:\n",
        "        return (p* (rp- ry) * 2).sum()\n",
        "\n",
        "def _norm_grad(grad, epsilon = 1e-6, eff_grad=None, sentence_level=False):\n",
        "        if sentence_level:\n",
        "            direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + epsilon)\n",
        "        else:\n",
        "            direction = grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "            eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "        return direction, eff_direction\n",
        "\n",
        "def noise(embed, model, attention_mask, step_size, normalize=False, k=1, mean=0, std=0.01):\n",
        "    if normalize == True:\n",
        "        \n",
        "        # LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n",
        "        # normalized_embed = LNorm(embed)\n",
        "        normalized_embed, embed_mean, embed_std = normalize_embed(embed)\n",
        "        logits = model.predict(normalized_embed,attention_mask)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(normalized_embed.size()[0],normalized_embed.size()[1],normalized_embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        adv_logits = model.predict(noised_normalized_embeddings, attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        denormalize_noised_embed = denormalize_embed(noised_normalized_embeddings,embed_mean, embed_std) \n",
        "        return denormalize_noised_embed\n",
        "\n",
        "    else:\n",
        "        logits = model.predict(embed,attention_mask)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(embed.size()[0],embed.size()[1],embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_embeddings = embed+noise\n",
        "        adv_logits = model.predict(noised_embeddings, attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_embeddings = embed+noise\n",
        "        return noised_embeddings\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bunW4qF4qSyZ"
      },
      "source": [
        "## Optimizer, Scheduler, and Some Other Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "#@title\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "#@title\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 3\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                          num_warmup_steps = 0,\n",
        "                          num_training_steps = total_steps\n",
        "                        )"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "#@title\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjvBSBfHtBc"
      },
      "source": [
        "MODE = \"SIFT\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCSpuOXLqor-"
      },
      "source": [
        "##Training Loop with Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a8f6e3-aa38-488a-f75c-592af1a22a51"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        embed = model.embed(input_ids = b_input_ids,mask = b_input_mask)\n",
        "        preds = model.predict(embedding_output = embed,attention_mask = b_input_mask)\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "        loss_list = [regular_loss]\n",
        "        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "          normalise = True if MODE == \"SIFT\" else False\n",
        "          noised_embeddings = noise(embed, model, b_input_mask, 1e-3, normalize=normalise, k=1)\n",
        "          adv_logits = model.predict(noised_embeddings, b_input_mask)\n",
        "\n",
        "          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "          loss_list.append(adv_loss)\n",
        "        loss = sum(loss_list)\n",
        "        # END MODEL\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    360.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    360.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    360.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    360.    Elapsed: 0:01:32.\n",
            "  Batch   200  of    360.    Elapsed: 0:01:54.\n",
            "  Batch   240  of    360.    Elapsed: 0:02:17.\n",
            "  Batch   280  of    360.    Elapsed: 0:02:40.\n",
            "  Batch   320  of    360.    Elapsed: 0:03:03.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:03:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.30\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    360.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    360.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    360.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    360.    Elapsed: 0:01:31.\n",
            "  Batch   200  of    360.    Elapsed: 0:01:54.\n",
            "  Batch   240  of    360.    Elapsed: 0:02:17.\n",
            "  Batch   280  of    360.    Elapsed: 0:02:40.\n",
            "  Batch   320  of    360.    Elapsed: 0:03:03.\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epcoh took: 0:03:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  Validation Loss: 0.24\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    360.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    360.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    360.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    360.    Elapsed: 0:01:31.\n",
            "  Batch   200  of    360.    Elapsed: 0:01:54.\n",
            "  Batch   240  of    360.    Elapsed: 0:02:17.\n",
            "  Batch   280  of    360.    Elapsed: 0:02:40.\n",
            "  Batch   320  of    360.    Elapsed: 0:03:03.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:03:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  Validation Loss: 0.26\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:10:25 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "8463937e-1a23-4be2-c4c9-577ea4511cd6"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.49</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0:03:26</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.36</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0:03:26</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0:03:26</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.49         0.30           0.88       0:03:26         0:00:03\n",
              "2               0.36         0.24           0.92       0:03:26         0:00:03\n",
              "3               0.25         0.26           0.92       0:03:26         0:00:03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "0d3c4349-da9e-4e56-9119-7f11dbfee610"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "##Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a7c00f-bce0-4818-b9bd-612df7d29bca"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = df_ori[2000:]\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.tweet.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,  \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   ) \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        " \n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 2,442\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "###Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b933b72e-8227-401d-9e64-30afc9b9cb45"
      },
      "source": [
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 2,442 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a816ccc0-6512-4f82-9b15-2734ba02f1df"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 1237 of 2442 (50.66%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097a8526-4e57-49d2-f572-b0f641f8dfeb"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "print(sum(flat_predictions == flat_true_labels)/len(flat_predictions))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9246519246519247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03n-Q5lipMan"
      },
      "source": [
        "## Test on UCI with/without Further Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMVge1-YOww5"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RxdwXhIpTAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "56d31dc7-987b-4044-d79e-c0cfbfeb07f8"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/amazon_cells_labelled.txt\"\n",
        "download = requests.get(url).content\n",
        "df_amazon = pd.read_csv(io.StringIO(download.decode('utf-8')),delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df_amazon.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  So there is no way for me to plug it in here i...      0\n",
              "1                        Good case, Excellent value.      1\n",
              "2                             Great for the jawbone.      1\n",
              "3  Tied to charger for conversations lasting more...      0\n",
              "4                                  The mic is great.      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7Zyw07QpwNN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "dfb0e655-a89b-4d39-f8c1-3daeaaae6e1f"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/yelp_labelled.txt\"\n",
        "download = requests.get(url).content\n",
        "df_yelp = pd.read_csv(io.StringIO(download.decode('utf-8')),delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df_yelp.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc8moBqOp2QL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "d5b6ad22-a3ef-4c54-d321-e45c4dfa3078"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/imdb_labelled.txt\"\n",
        "download = requests.get(url).content\n",
        "df_imdb = pd.read_csv(io.StringIO(download.decode('utf-8')),delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df_imdb.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  A very, very, very slow-moving, aimless movie ...      0\n",
              "1  Not sure who was more lost - the flat characte...      0\n",
              "2  Attempting artiness with black & white and cle...      0\n",
              "3       Very little music or anything to speak of.        0\n",
              "4  The best scene in the movie was when Gerardo i...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO1_TVbfqH4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "f17ea6e4-ae4e-4734-9c32-d8ea28e695ca"
      },
      "source": [
        "uci = pd.concat([df_imdb, df_amazon, df_yelp], axis = 0, join = 'inner')\n",
        "uci = uci.sample(frac = 1).reset_index(drop = True)\n",
        "uci.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's close to my house, it's low-key, non-fanc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you stay in Vegas you must get breakfast he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clipping this to your belt will deffinitely ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This is the phone to get for 2005.... I just b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i felt insulted and disrespected, how could yo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  It's close to my house, it's low-key, non-fanc...      1\n",
              "1  If you stay in Vegas you must get breakfast he...      1\n",
              "2  clipping this to your belt will deffinitely ma...      1\n",
              "3  This is the phone to get for 2005.... I just b...      1\n",
              "4  i felt insulted and disrespected, how could yo...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RjAHhEqO1O7"
      },
      "source": [
        "### Further Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQFbHqwEF9IL"
      },
      "source": [
        "# uci_further = uci[:270]\n",
        "# uci_test = uci[270:]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yhsX0zGGWA2"
      },
      "source": [
        "# optimizer = AdamW(model.parameters(),\n",
        "#                   lr = 2e-5,\n",
        "#                   eps = 1e-8 \n",
        "#                 )\n",
        "\n",
        "# from transformers import get_linear_schedule_with_warmup\n",
        "# epochs = 3\n",
        "# total_steps = len(train_dataloader) * epochs\n",
        "# scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "#                           num_warmup_steps = 0,\n",
        "#                           num_training_steps = total_steps\n",
        "#                         )\n",
        "\n",
        "\n",
        "# sentences = uci_further.Sentence.values\n",
        "# labels = uci_further.Label.values\n",
        "\n",
        "# input_ids = []\n",
        "# attention_masks = []\n",
        "# for sent in sentences:\n",
        "#     encoded_dict = tokenizer.encode_plus(\n",
        "#                         sent,\n",
        "#                         add_special_tokens = True,\n",
        "#                         max_length = 256,\n",
        "#                         pad_to_max_length = True,\n",
        "#                         return_attention_mask = True,\n",
        "#                         return_tensors = 'pt',\n",
        "#                    )    \n",
        "#     input_ids.append(encoded_dict['input_ids'])\n",
        "#     attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# input_ids = torch.cat(input_ids, dim=0)\n",
        "# attention_masks = torch.cat(attention_masks, dim=0)\n",
        "# labels = torch.tensor(labels)\n",
        "\n",
        "\n",
        "# from torch.utils.data import TensorDataset, random_split\n",
        "# dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "# train_size = int(0.9 * len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# print('{:>5,} training samples'.format(train_size))\n",
        "# print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "\n",
        "\n",
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# batch_size = 5\n",
        "\n",
        "# train_dataloader = DataLoader(\n",
        "#             train_dataset,\n",
        "#             sampler = RandomSampler(train_dataset),\n",
        "#             batch_size = batch_size\n",
        "#         )\n",
        "\n",
        "\n",
        "# validation_dataloader = DataLoader(\n",
        "#             val_dataset, \n",
        "#             sampler = SequentialSampler(val_dataset),\n",
        "#             batch_size = batch_size\n",
        "#         )\n",
        "\n",
        "\n",
        "\n",
        "# import random\n",
        "# import numpy as np\n",
        "\n",
        "# seed_val = 42\n",
        "\n",
        "# random.seed(seed_val)\n",
        "# np.random.seed(seed_val)\n",
        "# torch.manual_seed(seed_val)\n",
        "# torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# training_stats = []\n",
        "# total_t0 = time.time()\n",
        "\n",
        "# # For each epoch...\n",
        "# for epoch_i in range(0, epochs):\n",
        "    \n",
        "#     # ========================================\n",
        "#     #               Training\n",
        "#     # ========================================\n",
        "    \n",
        "#     # Perform one full pass over the training set.\n",
        "\n",
        "#     print(\"\")\n",
        "#     print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "#     print('Training...')\n",
        "\n",
        "#     # Measure how long the training epoch takes.\n",
        "#     t0 = time.time()\n",
        "#     total_train_loss = 0\n",
        "#     model.train()\n",
        "\n",
        "#     # For each batch of training data...\n",
        "#     for step, batch in enumerate(train_dataloader):\n",
        "#         # Progress update every 40 batches.\n",
        "#         if step % 40 == 0 and not step == 0:\n",
        "#             elapsed = format_time(time.time() - t0)\n",
        "#             print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "#         b_input_ids = batch[0].to(device)\n",
        "#         b_input_mask = batch[1].to(device)\n",
        "#         b_labels = batch[2].to(device)\n",
        "\n",
        "#         model.zero_grad()        \n",
        "\n",
        "#         embed = model.embed(input_ids = b_input_ids,mask = b_input_mask)\n",
        "#         preds = model.predict(embedding_output = embed,attention_mask = b_input_mask)\n",
        "#         loss_fct = CrossEntropyLoss()\n",
        "#         regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "#         loss_list = [regular_loss]\n",
        "#         if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "#           normalise = True if MODE == \"SIFT\" else False\n",
        "#           noised_embeddings = noise(embed, model, b_input_mask, 1e-3, normalize=normalise, k=1)\n",
        "#           adv_logits = model.predict(noised_embeddings, b_input_mask)\n",
        "\n",
        "#           adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "#           loss_list.append(adv_loss)\n",
        "#         loss = sum(loss_list)\n",
        "#         # END MODEL\n",
        "#         total_train_loss += loss.item()\n",
        "#         loss.backward()\n",
        "\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "#         optimizer.step()\n",
        "#         scheduler.step()\n",
        "\n",
        "#     avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "#     training_time = format_time(time.time() - t0)\n",
        "\n",
        "#     print(\"\")\n",
        "#     print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "#     print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "#     # ========================================\n",
        "#     #               Validation\n",
        "#     # ========================================\n",
        "#     # After the completion of each training epoch, measure our performance on\n",
        "#     # our validation set.\n",
        "\n",
        "#     print(\"\")\n",
        "#     print(\"Running Validation...\")\n",
        "\n",
        "#     t0 = time.time()\n",
        "#     model.eval()\n",
        "#     total_eval_accuracy = 0\n",
        "#     total_eval_loss = 0\n",
        "#     nb_eval_steps = 0\n",
        "\n",
        "#     # Evaluate data for one epoch\n",
        "#     for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "#         b_input_ids = batch[0].to(device)\n",
        "#         b_input_mask = batch[1].to(device)\n",
        "#         b_labels = batch[2].to(device)\n",
        "\n",
        "#         with torch.no_grad():        \n",
        "\n",
        "#             result = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "#                            attention_mask=b_input_mask,\n",
        "#                            labels=b_labels,\n",
        "#                            return_dict=True)\n",
        "\n",
        "\n",
        "#         loss = result.loss\n",
        "#         logits = result.logits\n",
        "\n",
        "#         total_eval_loss += loss.item()\n",
        "\n",
        "#         logits = logits.detach().cpu().numpy()\n",
        "#         label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "#         total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "#     avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "#     print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "#     avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "#     validation_time = format_time(time.time() - t0)\n",
        "#     print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "#     print(\"  Validation took: {:}\".format(validation_time))\n",
        "#     training_stats.append(\n",
        "#         {\n",
        "#             'epoch': epoch_i + 1,\n",
        "#             'Training Loss': avg_train_loss,\n",
        "#             'Valid. Loss': avg_val_loss,\n",
        "#             'Valid. Accur.': avg_val_accuracy,\n",
        "#             'Training Time': training_time,\n",
        "#             'Validation Time': validation_time\n",
        "#         }\n",
        "#     )\n",
        "\n",
        "# print(\"\")\n",
        "# print(\"Training complete!\")\n",
        "\n",
        "# print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgzBiz15Uy37"
      },
      "source": [
        "### Testing on The Remaining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_e6ugkbqq0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa34ccf-5bcc-4cf3-ba14-c8e9927313e5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(uci.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = uci.Sentence.values\n",
        "labels = uci.Label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,  \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   ) \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        " \n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 2,748\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwLgyw49q5W7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3be714b2-9b1e-45e6-d2b6-4e4fab9213de"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  #print(logits.sum())\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 2,748 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXkdm29TrB0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5613605e-422b-4f95-c107-32ed859a6685"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "print(np.sum(flat_predictions == flat_true_labels) / len(flat_true_labels))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.36717612809315864\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}