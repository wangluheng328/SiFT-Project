{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwitterUCI_Deberta_SMART_10%.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jJKaoairpdRa",
        "EFSJzwI5pujc",
        "hmSpMRD5qaqE",
        "bunW4qF4qSyZ"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dcb2b70f94a940fba9663dfb8fd6af2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f47f50aae8a34c109cba05b1a6e0689f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b853a39807354e9abc7d668075fc2707",
              "IPY_MODEL_7c52a4c2ddea4052b44c4ed17ef87ec5"
            ]
          }
        },
        "f47f50aae8a34c109cba05b1a6e0689f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b853a39807354e9abc7d668075fc2707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4eff75e5c86a41e38fd55c2cae2d529e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898825,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898825,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_469d633337ba4b938ca3fcd7aeecc8b3"
          }
        },
        "7c52a4c2ddea4052b44c4ed17ef87ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_533c4cfd4a50418e875e0ad6d4753eb0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 1.02MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2b37f7f9f2848caaf0068aea01d1f7d"
          }
        },
        "4eff75e5c86a41e38fd55c2cae2d529e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "469d633337ba4b938ca3fcd7aeecc8b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "533c4cfd4a50418e875e0ad6d4753eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2b37f7f9f2848caaf0068aea01d1f7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12d1bb5457e648d78e0231c04ba58cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab6acdb8c29444c5803643d9563ac75b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_541978ee1805411e880dcd78c905e956",
              "IPY_MODEL_3b9178afacea4905b6b890cdbb493d50"
            ]
          }
        },
        "ab6acdb8c29444c5803643d9563ac75b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "541978ee1805411e880dcd78c905e956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b67bdceb811c4c8898555f52c510f4d1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a39a1539d244f63a9e33a083e8344e5"
          }
        },
        "3b9178afacea4905b6b890cdbb493d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d0c6f860a4794da68eace083ef0dfe9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.16MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72ba3124ee144d51846f7003ba68cc68"
          }
        },
        "b67bdceb811c4c8898555f52c510f4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a39a1539d244f63a9e33a083e8344e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0c6f860a4794da68eace083ef0dfe9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72ba3124ee144d51846f7003ba68cc68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9da5955efdd40efa57b160118549491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6589cb86630b404f9e9956c50bf34f63",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7eccc799ddd946258fc665b02213cb91",
              "IPY_MODEL_9705c0cd2cb545ebb00dd20f4d44ee68"
            ]
          }
        },
        "6589cb86630b404f9e9956c50bf34f63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7eccc799ddd946258fc665b02213cb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5cb04e511f5541cdb631d5e00dec7cf9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 52,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 52,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04f164cd2b2c4563bca8da560fa208a2"
          }
        },
        "9705c0cd2cb545ebb00dd20f4d44ee68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_75fdd6e46353405f9d6890b315b2a20a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 52.0/52.0 [00:00&lt;00:00, 342B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_abef9d9225c74b1aa612b0359e004293"
          }
        },
        "5cb04e511f5541cdb631d5e00dec7cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04f164cd2b2c4563bca8da560fa208a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75fdd6e46353405f9d6890b315b2a20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "abef9d9225c74b1aa612b0359e004293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64e1b21e6a3d4304b9413c67408bc089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_df352ab60f3c4abc99ca80c8b4cb0f97",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_28c7f0a350894a6aa489625348de8ac2",
              "IPY_MODEL_568315e336de4265b03d0db30f5c31a5"
            ]
          }
        },
        "df352ab60f3c4abc99ca80c8b4cb0f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28c7f0a350894a6aa489625348de8ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_24a88849003a4c75becf1e6b4bb5df57",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 474,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 474,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8987b7d9c005415cb86d61afd2f370c3"
          }
        },
        "568315e336de4265b03d0db30f5c31a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fead66aed70845b3893e521bdf628d85",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 474/474 [00:00&lt;00:00, 1.91kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15f72b21b49d4bb999a9e5a59a53aab9"
          }
        },
        "24a88849003a4c75becf1e6b4bb5df57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8987b7d9c005415cb86d61afd2f370c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fead66aed70845b3893e521bdf628d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15f72b21b49d4bb999a9e5a59a53aab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17f5a535645f45da857ce434bb309b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80cf013c715749b981246833dad4c32c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c806afc33ab45fca0a1f7380815b5f1",
              "IPY_MODEL_c653453a12df4b84a3f5d6233e1a4d16"
            ]
          }
        },
        "80cf013c715749b981246833dad4c32c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c806afc33ab45fca0a1f7380815b5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11f7b47770994354abca354153ae8489",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 558582766,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 558582766,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fbc1d43526f4dc098ce3251fd6f1855"
          }
        },
        "c653453a12df4b84a3f5d6233e1a4d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d654317f3da04beb9069568b0e5bffa9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 559M/559M [00:16&lt;00:00, 34.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21f18eb7d578411584bfe05376efffbd"
          }
        },
        "11f7b47770994354abca354153ae8489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fbc1d43526f4dc098ce3251fd6f1855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d654317f3da04beb9069568b0e5bffa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21f18eb7d578411584bfe05376efffbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# DeBERTa Fine-Tuning on CoLA with SMART and SiFT\n",
        "\n",
        "This notebook was orginally created by Chris McCormick and Nick Ryan. We made changes for SiFT and SMART, as well as our custom BERT/DeBERTa class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJKaoairpdRa"
      },
      "source": [
        "##Data and Importing Modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "025c4f23-95c0-45a3-e5cb-99dbcf29de42"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65fac863-f8f1-4731-e931-7f50c9771337"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77345edd-ad8d-490f-da83-c661f0515df8"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 28.4MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5553756d-731a-4870-a2c8-879a381f212d"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=e12b7bb698a4bab3013bccc00a6707c55877dc23043027f91f5aa77745109a12\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FBXpjYJ0iHcp",
        "outputId": "2c6a44b4-798a-49c0-bade-b1d8dd43dd94"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/fourth.csv\"\n",
        "download = requests.get(url).content\n",
        "df = pd.read_csv(io.StringIO(download.decode('utf-8')),index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label                                              tweet\n",
              "id                                                          \n",
              "1       0   @user when a father is dysfunctional and is s...\n",
              "2       0  @user @user thanks for #lyft credit i can't us...\n",
              "3       0                                bihday your majesty\n",
              "4       0  #model   i love u take with u all the time in ...\n",
              "5       0             factsguide: society now    #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5K7JlQ-BPts"
      },
      "source": [
        "df1 = df[df['label']==1]\n",
        "df0 = df[df['label']==0]\n",
        "df0 = df0[:2200]\n",
        "df_ori = pd.concat([df0, df1], axis = 0, join = 'inner')\n",
        "df_ori = df_ori.sample(frac = 1).reset_index(drop = True)\n",
        "df = df_ori[:2000]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MvfL3MLjBsqb",
        "outputId": "0a5b487d-0242-4c0a-e6f6-3a29dae608fe"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>beautiful (: i love living at the beach!!!! #b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>@user @user @user @user over the past 8 yrs #d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>@user dear #democrats , djt not allowing #isla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>chase your   ð   #dreams #health #music #fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>feels like summer ð´ðð   #love #like #...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                              tweet\n",
              "0      0  beautiful (: i love living at the beach!!!! #b...\n",
              "1      1  @user @user @user @user over the past 8 yrs #d...\n",
              "2      1  @user dear #democrats , djt not allowing #isla...\n",
              "3      0  chase your   ð   #dreams #health #music #fi...\n",
              "4      0  feels like summer ð´ðð   #love #like #..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOPpgw4Gi6hc"
      },
      "source": [
        "sentences = df.tweet.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RAaRTCcDCOA",
        "outputId": "a25c53c8-9f4f-49e0-faba-785dfb647bd2"
      },
      "source": [
        "labels.sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFSJzwI5pujc"
      },
      "source": [
        "## Tokenization and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "dcb2b70f94a940fba9663dfb8fd6af2e",
            "f47f50aae8a34c109cba05b1a6e0689f",
            "b853a39807354e9abc7d668075fc2707",
            "7c52a4c2ddea4052b44c4ed17ef87ec5",
            "4eff75e5c86a41e38fd55c2cae2d529e",
            "469d633337ba4b938ca3fcd7aeecc8b3",
            "533c4cfd4a50418e875e0ad6d4753eb0",
            "e2b37f7f9f2848caaf0068aea01d1f7d",
            "12d1bb5457e648d78e0231c04ba58cdf",
            "ab6acdb8c29444c5803643d9563ac75b",
            "541978ee1805411e880dcd78c905e956",
            "3b9178afacea4905b6b890cdbb493d50",
            "b67bdceb811c4c8898555f52c510f4d1",
            "0a39a1539d244f63a9e33a083e8344e5",
            "d0c6f860a4794da68eace083ef0dfe9e",
            "72ba3124ee144d51846f7003ba68cc68",
            "d9da5955efdd40efa57b160118549491",
            "6589cb86630b404f9e9956c50bf34f63",
            "7eccc799ddd946258fc665b02213cb91",
            "9705c0cd2cb545ebb00dd20f4d44ee68",
            "5cb04e511f5541cdb631d5e00dec7cf9",
            "04f164cd2b2c4563bca8da560fa208a2",
            "75fdd6e46353405f9d6890b315b2a20a",
            "abef9d9225c74b1aa612b0359e004293"
          ]
        },
        "outputId": "850ac30c-1913-4253-bb1f-6ce3450baa19"
      },
      "source": [
        "from transformers import DebertaTokenizer\n",
        "print('Loading DeBERTa tokenizer...')\n",
        "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading DeBERTa tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dcb2b70f94a940fba9663dfb8fd6af2e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898825.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12d1bb5457e648d78e0231c04ba58cdf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9da5955efdd40efa57b160118549491",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=52.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f19facb-bfc8-49e9-a95e-4e866d5d2af6"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  beautiful (: i love living at the beach!!!! #beach #loveit   \n",
            "Tokenized:  ['beaut', 'iful', 'Ġ(', ':', 'Ġi', 'Ġlove', 'Ġliving', 'Ġat', 'Ġthe', 'Ġbeach', '!!!!', 'Ġ#', 'be', 'ach', 'Ġ#', 'love', 'it', 'Ġ', 'Ġ', 'Ġ']\n",
            "Token IDs:  [28878, 16170, 36, 35, 939, 657, 1207, 23, 5, 4105, 32376, 849, 1610, 1488, 849, 17693, 405, 1437, 1437, 1437]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5847d05e-21bc-464b-ac10-32faab0439ea"
      },
      "source": [
        "max_len = 0\n",
        "for sent in sentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61569aed-9590-4bd5-86a9-82eae87f6eba"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  beautiful (: i love living at the beach!!!! #beach #loveit   \n",
            "Token IDs: tensor([    1, 28878, 16170,    36,    35,   939,   657,  1207,    23,     5,\n",
            "         4105, 32376,   849,  1610,  1488,   849, 17693,   405,  1437,  1437,\n",
            "         1437,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60421aec-c82b-42a7-f889-e1743b0c0f0b"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,800 training samples\n",
            "  200 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73S4P4SMp6hX"
      },
      "source": [
        "## Custom Deberta Class and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOteWAT-Adqx"
      },
      "source": [
        "from transformers import DebertaForSequenceClassification, AdamW, DebertaConfig, DebertaPreTrainedModel, DebertaModel\n",
        "from transformers.models.deberta.modeling_deberta import *\n",
        "#from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "class CustomDebertaForClassification(DebertaForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        #self.bert = BertForSequenceClassification(config).from_pretrained(\"bert-base-uncased\",num_labels = 2,output_attentions = False, output_hidden_states = False)\n",
        "        self.embeddings = self.deberta.embeddings\n",
        "        self.encoder = self.deberta.encoder\n",
        "        self.z_steps = 0 #copied from DebertaModel source code\n",
        "\n",
        "\n",
        "    def embed(self, input_ids=None, \n",
        "                    mask=None,\n",
        "                    token_type_ids=None, \n",
        "                    position_ids=None, \n",
        "                    inputs_embeds=None\n",
        "                    ):\n",
        "        # See: BERTModel.forward\n",
        "        return self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            mask=mask,\n",
        "            inputs_embeds=inputs_embeds\n",
        "        )\n",
        "    \n",
        "    def predict(self,embedding_output,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_extended_attention_mask=None,\n",
        "                past_key_values=None,\n",
        "                use_cache=None,\n",
        "                output_attentions=None,\n",
        "                output_hidden_states=None,\n",
        "                return_dict=True): \n",
        "        encoder_outputs = self.encoder(\n",
        "                                        embedding_output,\n",
        "                                        attention_mask,\n",
        "                                        output_hidden_states=True,\n",
        "                                        output_attentions=output_attentions,\n",
        "                                        return_dict=return_dict\n",
        "        )\n",
        "        encoded_layers = encoder_outputs[1]\n",
        "\n",
        "        if self.z_steps > 1:\n",
        "            hidden_states = encoded_layers[-2]\n",
        "            layers = [self.encoder.layer[-1] for _ in range(self.z_steps)]\n",
        "            query_states = encoded_layers[-1]\n",
        "            rel_embeddings = self.encoder.get_rel_embedding()\n",
        "            attention_mask = self.encoder.get_attention_mask(attention_mask)\n",
        "            rel_pos = self.encoder.get_rel_pos(embedding_output)\n",
        "            for layer in layers[1:]:\n",
        "                query_states = layer(\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    return_att=False,\n",
        "                    query_states=query_states,\n",
        "                    relative_pos=rel_pos,\n",
        "                    rel_embeddings=rel_embeddings,\n",
        "                )\n",
        "                encoded_layers.append(query_states)\n",
        "\n",
        "        sequence_output = encoded_layers[-1]\n",
        "\n",
        "        # if not return_dict:\n",
        "        #     return (sequence_output,) + encoder_outputs[(1 if output_hidden_states else 2) :]\n",
        "\n",
        "        outputs = BaseModelOutput(\n",
        "            last_hidden_state=sequence_output,\n",
        "            hidden_states=encoder_outputs.hidden_states if output_hidden_states else None,\n",
        "            attentions=encoder_outputs.attentions,\n",
        "        )\n",
        "\n",
        "        \n",
        "\n",
        "        pooled_output = self.pooler(outputs[0])\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        return logits\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "64e1b21e6a3d4304b9413c67408bc089",
            "df352ab60f3c4abc99ca80c8b4cb0f97",
            "28c7f0a350894a6aa489625348de8ac2",
            "568315e336de4265b03d0db30f5c31a5",
            "24a88849003a4c75becf1e6b4bb5df57",
            "8987b7d9c005415cb86d61afd2f370c3",
            "fead66aed70845b3893e521bdf628d85",
            "15f72b21b49d4bb999a9e5a59a53aab9",
            "17f5a535645f45da857ce434bb309b26",
            "80cf013c715749b981246833dad4c32c",
            "0c806afc33ab45fca0a1f7380815b5f1",
            "c653453a12df4b84a3f5d6233e1a4d16",
            "11f7b47770994354abca354153ae8489",
            "8fbc1d43526f4dc098ce3251fd6f1855",
            "d654317f3da04beb9069568b0e5bffa9",
            "21f18eb7d578411584bfe05376efffbd"
          ]
        },
        "id": "IdNBO5qk2-i_",
        "collapsed": true,
        "outputId": "8ce208c7-a3b3-4189-9277-18097995389e"
      },
      "source": [
        "#@title\n",
        "model = CustomDebertaForClassification.from_pretrained(\n",
        "    \"microsoft/deberta-base\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64e1b21e6a3d4304b9413c67408bc089",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=474.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17f5a535645f45da857ce434bb309b26",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=558582766.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing CustomDebertaForClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'config']\n",
            "- This IS expected if you are initializing CustomDebertaForClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomDebertaForClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomDebertaForClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['encoder.layer.5.attention.self.in_proj.weight', 'encoder.layer.11.attention.self.v_bias', 'encoder.layer.3.attention.self.q_bias', 'encoder.rel_embeddings.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.2.attention.self.pos_proj.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.self.q_bias', 'encoder.layer.4.attention.self.pos_q_proj.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.pos_q_proj.weight', 'encoder.layer.11.attention.self.in_proj.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.attention.self.pos_proj.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.10.attention.self.in_proj.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.self.pos_q_proj.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.in_proj.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.v_bias', 'encoder.layer.9.attention.self.in_proj.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.attention.self.q_bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.self.q_bias', 'encoder.layer.4.attention.self.pos_proj.weight', 'encoder.layer.8.attention.self.v_bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.attention.self.pos_q_proj.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.pos_proj.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.5.attention.self.v_bias', 'encoder.layer.5.attention.self.pos_q_proj.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.11.attention.self.pos_q_proj.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'classifier.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.6.attention.self.pos_proj.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.attention.self.v_bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.attention.self.pos_q_proj.weight', 'encoder.layer.2.attention.self.v_bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.pos_q_proj.weight', 'encoder.layer.5.intermediate.dense.weight', 'pooler.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.pos_q_proj.bias', 'encoder.layer.3.attention.self.pos_proj.weight', 'classifier.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.q_bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.self.v_bias', 'encoder.layer.1.attention.self.in_proj.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.attention.self.q_bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.pos_q_proj.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.3.attention.self.pos_q_proj.bias', 'encoder.layer.1.attention.self.pos_proj.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.5.attention.self.pos_proj.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.pos_q_proj.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.self.v_bias', 'encoder.layer.0.attention.self.in_proj.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.0.attention.self.pos_proj.weight', 'encoder.layer.4.attention.self.q_bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.1.attention.self.pos_q_proj.bias', 'encoder.layer.5.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.attention.self.v_bias', 'encoder.layer.3.attention.self.pos_q_proj.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.self.v_bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.pos_q_proj.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.q_bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.q_bias', 'encoder.layer.5.attention.self.pos_q_proj.bias', 'encoder.layer.2.attention.self.pos_q_proj.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.attention.self.pos_q_proj.bias', 'encoder.layer.10.attention.self.pos_q_proj.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.in_proj.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.attention.self.pos_q_proj.weight', 'encoder.layer.8.attention.self.pos_proj.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.self.v_bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.in_proj.weight', 'encoder.layer.1.attention.self.pos_q_proj.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.in_proj.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.attention.self.pos_q_proj.weight', 'encoder.layer.4.attention.self.pos_q_proj.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.q_bias', 'encoder.layer.5.attention.self.q_bias', 'encoder.layer.7.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.attention.self.q_bias', 'encoder.layer.4.attention.self.in_proj.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.pos_proj.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.self.pos_proj.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.in_proj.weight', 'encoder.layer.9.attention.self.v_bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.0.attention.self.pos_q_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomDebertaForClassification(\n",
              "  (deberta): DebertaModel(\n",
              "    (embeddings): DebertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "      (LayerNorm): DebertaLayerNorm()\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (1): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (2): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (3): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (4): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (5): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (6): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (7): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (8): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (9): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (10): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (11): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(1024, 768)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): StableDropout()\n",
              "  (embeddings): DebertaEmbeddings(\n",
              "    (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "    (LayerNorm): DebertaLayerNorm()\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (encoder): DebertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (1): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (2): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (3): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (4): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (5): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (6): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (7): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (8): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (9): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (10): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (11): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (rel_embeddings): Embedding(1024, 768)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmSpMRD5qaqE"
      },
      "source": [
        "##Noise Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG5DszcpDAjw"
      },
      "source": [
        "from torch.nn import LayerNorm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def normalize_embed(embed):\n",
        "    embed_mean = torch.mean(embed,dim=(1,2))\n",
        "    embed_std = torch.std(embed, dim=(1,2))\n",
        "\n",
        "    embed_clone = torch.clone(embed)\n",
        "\n",
        "    for i in range(0,embed_clone.size()[0]):\n",
        "        # embed_clone[i] = torch.div(torch.sub(embed_clone[i],embed_mean[i]),embed_std[i])\n",
        "        embed_clone[i] = (embed_clone[i] - embed_mean[i]) / embed_std[i]\n",
        "    return embed_clone, embed_mean, embed_std\n",
        "\n",
        "def denormalize_embed(embed, embed_mean, embed_std):\n",
        "    for i in range(0,embed.size()[0]):\n",
        "        # embed[i] = (embed[i] - embed_mean[i]) / embed_std[i]\n",
        "        embed[i] = (embed[i] * embed_std[i]) + embed_mean[i]\n",
        "    return embed \n",
        "\n",
        "def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n",
        "    logit = logit.view(-1, logit.size(-1)).float()\n",
        "    target = target.view(-1, target.size(-1)).float()\n",
        "    bs = logit.size(0)\n",
        "    p = F.log_softmax(logit, 1).exp()\n",
        "    y = F.log_softmax(target, 1).exp()\n",
        "    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n",
        "    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n",
        "    if reduce:\n",
        "        return (p* (rp- ry) * 2).sum() / bs\n",
        "    else:\n",
        "        return (p* (rp- ry) * 2).sum()\n",
        "\n",
        "def _norm_grad(grad, epsilon = 1e-6, eff_grad=None, sentence_level=False):\n",
        "        if sentence_level:\n",
        "            direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + epsilon)\n",
        "        else:\n",
        "            direction = grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "            eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "        return direction, eff_direction\n",
        "\n",
        "def noise(embed, model, attention_mask, step_size, normalize=False, k=1, mean=0, std=0.01):\n",
        "    if normalize == True:\n",
        "        \n",
        "        # LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n",
        "        # normalized_embed = LNorm(embed)\n",
        "        normalized_embed, embed_mean, embed_std = normalize_embed(embed)\n",
        "        logits = model.predict(normalized_embed,attention_mask)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(normalized_embed.size()[0],normalized_embed.size()[1],normalized_embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        adv_logits = model.predict(noised_normalized_embeddings, attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        denormalize_noised_embed = denormalize_embed(noised_normalized_embeddings,embed_mean, embed_std) \n",
        "        return denormalize_noised_embed\n",
        "\n",
        "    else:\n",
        "        logits = model.predict(embed,attention_mask)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(embed.size()[0],embed.size()[1],embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_embeddings = embed+noise\n",
        "        adv_logits = model.predict(noised_embeddings, attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_embeddings = embed+noise\n",
        "        return noised_embeddings\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bunW4qF4qSyZ"
      },
      "source": [
        "## Optimizer, Scheduler, and Some Other Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "#@title\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "#@title\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                          num_warmup_steps = 0,\n",
        "                          num_training_steps = total_steps\n",
        "                        )"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "#@title\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjvBSBfHtBc"
      },
      "source": [
        "MODE = \"SMART-adv-only\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCSpuOXLqor-"
      },
      "source": [
        "##Training Loop with Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "461e393a-326f-4ea8-b970-7917a6a72341"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        embed = model.embed(input_ids = b_input_ids,mask = b_input_mask)\n",
        "        preds = model.predict(embedding_output = embed,attention_mask = b_input_mask)\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "        loss_list = [regular_loss]\n",
        "        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "          normalise = True if MODE == \"SIFT\" else False\n",
        "          noised_embeddings = noise(embed, model, b_input_mask, 1e-3, normalize=normalise, k=1)\n",
        "          adv_logits = model.predict(noised_embeddings, b_input_mask)\n",
        "\n",
        "          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "          loss_list.append(adv_loss)\n",
        "        loss = sum(loss_list)\n",
        "        # END MODEL\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of    360.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    360.    Elapsed: 0:00:46.\n",
            "  Batch   120  of    360.    Elapsed: 0:01:09.\n",
            "  Batch   160  of    360.    Elapsed: 0:01:32.\n",
            "  Batch   200  of    360.    Elapsed: 0:01:55.\n",
            "  Batch   240  of    360.    Elapsed: 0:02:18.\n",
            "  Batch   280  of    360.    Elapsed: 0:02:41.\n",
            "  Batch   320  of    360.    Elapsed: 0:03:04.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:03:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:03:29 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "71543b94-48f0-4af0-c272-eadc86b89aa1"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.52</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0:03:26</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.52         0.18           0.93       0:03:26         0:00:03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "8bf6b397-98c6-4291-cc5b-bf3ada6ac46b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "##Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e746e9b-79d1-42f3-fa65-a7ae08deed39"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = df_ori[2000:]\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.tweet.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,  \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   ) \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        " \n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 2,442\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "###Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9aaa359-278a-42f5-9ff0-fc4639a3209a"
      },
      "source": [
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 2,442 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd106923-3808-4cc6-af1c-5da1a37aba5e"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 1233 of 2442 (50.49%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45105d60-e6a9-48d0-b674-006a8930b8a6"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "print(sum(flat_predictions == flat_true_labels)/len(flat_predictions))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9058149058149059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03n-Q5lipMan"
      },
      "source": [
        "## Test on UCI with/without Further Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMVge1-YOww5"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RxdwXhIpTAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "eaa8b940-131a-4723-ca3f-1dc9ea7b7c51"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/amazon_cells_labelled.txt\"\n",
        "download = requests.get(url).content\n",
        "df_amazon = pd.read_csv(io.StringIO(download.decode('utf-8')),delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df_amazon.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  So there is no way for me to plug it in here i...      0\n",
              "1                        Good case, Excellent value.      1\n",
              "2                             Great for the jawbone.      1\n",
              "3  Tied to charger for conversations lasting more...      0\n",
              "4                                  The mic is great.      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7Zyw07QpwNN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "5c685b53-e4a1-4065-87a5-7cb7d94dfde5"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/yelp_labelled.txt\"\n",
        "download = requests.get(url).content\n",
        "df_yelp = pd.read_csv(io.StringIO(download.decode('utf-8')),delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df_yelp.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc8moBqOp2QL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "c4c2d776-e6b3-4e82-ad24-1d6cf6f06cf3"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/imdb_labelled.txt\"\n",
        "download = requests.get(url).content\n",
        "df_imdb = pd.read_csv(io.StringIO(download.decode('utf-8')),delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df_imdb.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  A very, very, very slow-moving, aimless movie ...      0\n",
              "1  Not sure who was more lost - the flat characte...      0\n",
              "2  Attempting artiness with black & white and cle...      0\n",
              "3       Very little music or anything to speak of.        0\n",
              "4  The best scene in the movie was when Gerardo i...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO1_TVbfqH4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "92f3796c-593d-4d1c-cd25-2241e211780a"
      },
      "source": [
        "uci = pd.concat([df_imdb, df_amazon, df_yelp], axis = 0, join = 'inner')\n",
        "uci = uci.sample(frac = 1).reset_index(drop = True)\n",
        "uci.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's close to my house, it's low-key, non-fanc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you stay in Vegas you must get breakfast he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clipping this to your belt will deffinitely ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This is the phone to get for 2005.... I just b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i felt insulted and disrespected, how could yo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  It's close to my house, it's low-key, non-fanc...      1\n",
              "1  If you stay in Vegas you must get breakfast he...      1\n",
              "2  clipping this to your belt will deffinitely ma...      1\n",
              "3  This is the phone to get for 2005.... I just b...      1\n",
              "4  i felt insulted and disrespected, how could yo...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RjAHhEqO1O7"
      },
      "source": [
        "### Further Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQFbHqwEF9IL"
      },
      "source": [
        "uci_further = uci[:270]\n",
        "uci_test = uci[270:]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yhsX0zGGWA2",
        "outputId": "782597f7-19fe-4391-e44d-9496b26135dd"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 \n",
        "                )\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 3\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                          num_warmup_steps = 0,\n",
        "                          num_training_steps = total_steps\n",
        "                        )\n",
        "\n",
        "\n",
        "sentences = uci_further.Sentence.values\n",
        "labels = uci_further.Label.values\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        embed = model.embed(input_ids = b_input_ids,mask = b_input_mask)\n",
        "        preds = model.predict(embedding_output = embed,attention_mask = b_input_mask)\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "        loss_list = [regular_loss]\n",
        "        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "          normalise = True if MODE == \"SIFT\" else False\n",
        "          noised_embeddings = noise(embed, model, b_input_mask, 1e-3, normalize=normalise, k=1)\n",
        "          adv_logits = model.predict(noised_embeddings, b_input_mask)\n",
        "\n",
        "          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "          loss_list.append(adv_loss)\n",
        "        loss = sum(loss_list)\n",
        "        # END MODEL\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  243 training samples\n",
            "   27 validation samples\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of     49.    Elapsed: 0:00:23.\n",
            "\n",
            "  Average training loss: 0.82\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of     49.    Elapsed: 0:00:23.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.76\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of     49.    Elapsed: 0:00:23.\n",
            "\n",
            "  Average training loss: 0.68\n",
            "  Training epcoh took: 0:00:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.70\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:01:24 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgzBiz15Uy37"
      },
      "source": [
        "### Testing on The Remaining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_e6ugkbqq0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52bb3a84-ffe2-4d13-883b-40b4ab12a8b8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(uci_test.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = uci_test.Sentence.values\n",
        "labels = uci_test.Label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,  \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   ) \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        " \n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 2,478\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwLgyw49q5W7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d779cfa-c9a6-416e-991a-c7ab77feb992"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  #print(logits.sum())\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 2,478 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXkdm29TrB0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d314dd7d-4ed7-4788-b3c0-a866ed80a8c3"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "print(np.sum(flat_predictions == flat_true_labels) / len(flat_true_labels))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8087167070217918\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}