{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwitterUCI_Deberta_SMART_0%.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jJKaoairpdRa",
        "EFSJzwI5pujc",
        "hmSpMRD5qaqE",
        "bunW4qF4qSyZ"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# DeBERTa Fine-Tuning on CoLA with SMART and SiFT\n",
        "\n",
        "This notebook was orginally created by Chris McCormick and Nick Ryan. We made changes for SiFT and SMART, as well as our custom BERT/DeBERTa class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJKaoairpdRa"
      },
      "source": [
        "##Data and Importing Modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b6beb69-f4a7-4aa1-efee-d88a5b7bd8c7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48040675-d522-46a3-c07d-7d26d2059f37"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feed803f-b098-4780-c7ed-b64307526f26"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "316f7b60-3091-4b7b-b9e9-234dc74c4218"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FBXpjYJ0iHcp",
        "outputId": "a0a3aed1-3d8d-4b78-9659-47806d2a1473"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/fourth.csv\"\n",
        "download = requests.get(url).content\n",
        "df = pd.read_csv(io.StringIO(download.decode('utf-8')),index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label                                              tweet\n",
              "id                                                          \n",
              "1       0   @user when a father is dysfunctional and is s...\n",
              "2       0  @user @user thanks for #lyft credit i can't us...\n",
              "3       0                                bihday your majesty\n",
              "4       0  #model   i love u take with u all the time in ...\n",
              "5       0             factsguide: society now    #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5K7JlQ-BPts"
      },
      "source": [
        "df1 = df[df['label']==1]\n",
        "df0 = df[df['label']==0]\n",
        "df0 = df0[:2200]\n",
        "df_ori = pd.concat([df0, df1], axis = 0, join = 'inner')\n",
        "df_ori = df_ori.sample(frac = 1).reset_index(drop = True)\n",
        "df = df_ori[:2000]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MvfL3MLjBsqb",
        "outputId": "082a163c-bd59-4d8b-8565-e52ebd552e5d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>i fixed the washing machine !!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user as forecasted, the beautiful waves of r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>rajo to all..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>hello! #sunglasses #notmine #darkerhair #explo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>victim of #islamophobia adam saleh refers to ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                              tweet\n",
              "0      0                  i fixed the washing machine !!!  \n",
              "1      0   @user as forecasted, the beautiful waves of r...\n",
              "2      0                                     rajo to all.. \n",
              "3      0  hello! #sunglasses #notmine #darkerhair #explo...\n",
              "4      1   victim of #islamophobia adam saleh refers to ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOPpgw4Gi6hc"
      },
      "source": [
        "sentences = df.tweet.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RAaRTCcDCOA",
        "outputId": "e74e3ed5-f1a4-4257-dcbb-d04445a0a497"
      },
      "source": [
        "labels.sum()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "973"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFSJzwI5pujc"
      },
      "source": [
        "## Tokenization and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8445c84b-80d2-43be-ff04-20ee1c558d87"
      },
      "source": [
        "from transformers import DebertaTokenizer\n",
        "print('Loading DeBERTa tokenizer...')\n",
        "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base', do_lower_case=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading DeBERTa tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018ac02c-8ca2-4c72-855c-b1e831f9bcdb"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  i fixed the washing machine !!!  \n",
            "Tokenized:  ['i', 'Ġfixed', 'Ġthe', 'Ġwashing', 'Ġmachine', 'Ġ', '!!!', 'Ġ', 'Ġ']\n",
            "Token IDs:  [118, 4460, 5, 14784, 3563, 1437, 16506, 1437, 1437]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d250a792-baaa-46e0-c15c-022ffacb1b88"
      },
      "source": [
        "max_len = 0\n",
        "for sent in sentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa53772a-0444-449f-f89a-1313426aa85c"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  i fixed the washing machine !!!  \n",
            "Token IDs: tensor([    1,   118,  4460,     5, 14784,  3563,  1437, 16506,  1437,  1437,\n",
            "            2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c482dc8d-a632-45b5-fd3b-dc815aed62d1"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,800 training samples\n",
            "  200 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73S4P4SMp6hX"
      },
      "source": [
        "## Custom Deberta Class and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOteWAT-Adqx"
      },
      "source": [
        "from transformers import DebertaForSequenceClassification, AdamW, DebertaConfig, DebertaPreTrainedModel, DebertaModel\n",
        "from transformers.models.deberta.modeling_deberta import *\n",
        "#from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "class CustomDebertaForClassification(DebertaForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        #self.bert = BertForSequenceClassification(config).from_pretrained(\"bert-base-uncased\",num_labels = 2,output_attentions = False, output_hidden_states = False)\n",
        "        self.embeddings = self.deberta.embeddings\n",
        "        self.encoder = self.deberta.encoder\n",
        "        self.z_steps = 0 #copied from DebertaModel source code\n",
        "\n",
        "\n",
        "    def embed(self, input_ids=None, \n",
        "                    mask=None,\n",
        "                    token_type_ids=None, \n",
        "                    position_ids=None, \n",
        "                    inputs_embeds=None\n",
        "                    ):\n",
        "        # See: BERTModel.forward\n",
        "        return self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            mask=mask,\n",
        "            inputs_embeds=inputs_embeds\n",
        "        )\n",
        "    \n",
        "    def predict(self,embedding_output,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_extended_attention_mask=None,\n",
        "                past_key_values=None,\n",
        "                use_cache=None,\n",
        "                output_attentions=None,\n",
        "                output_hidden_states=None,\n",
        "                return_dict=True): \n",
        "        encoder_outputs = self.encoder(\n",
        "                                        embedding_output,\n",
        "                                        attention_mask,\n",
        "                                        output_hidden_states=True,\n",
        "                                        output_attentions=output_attentions,\n",
        "                                        return_dict=return_dict\n",
        "        )\n",
        "        encoded_layers = encoder_outputs[1]\n",
        "\n",
        "        if self.z_steps > 1:\n",
        "            hidden_states = encoded_layers[-2]\n",
        "            layers = [self.encoder.layer[-1] for _ in range(self.z_steps)]\n",
        "            query_states = encoded_layers[-1]\n",
        "            rel_embeddings = self.encoder.get_rel_embedding()\n",
        "            attention_mask = self.encoder.get_attention_mask(attention_mask)\n",
        "            rel_pos = self.encoder.get_rel_pos(embedding_output)\n",
        "            for layer in layers[1:]:\n",
        "                query_states = layer(\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    return_att=False,\n",
        "                    query_states=query_states,\n",
        "                    relative_pos=rel_pos,\n",
        "                    rel_embeddings=rel_embeddings,\n",
        "                )\n",
        "                encoded_layers.append(query_states)\n",
        "\n",
        "        sequence_output = encoded_layers[-1]\n",
        "\n",
        "        # if not return_dict:\n",
        "        #     return (sequence_output,) + encoder_outputs[(1 if output_hidden_states else 2) :]\n",
        "\n",
        "        outputs = BaseModelOutput(\n",
        "            last_hidden_state=sequence_output,\n",
        "            hidden_states=encoder_outputs.hidden_states if output_hidden_states else None,\n",
        "            attentions=encoder_outputs.attentions,\n",
        "        )\n",
        "\n",
        "        \n",
        "\n",
        "        pooled_output = self.pooler(outputs[0])\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        return logits\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdNBO5qk2-i_",
        "collapsed": true,
        "outputId": "e0de005c-0e97-4ca1-e7a8-49079bfa7674"
      },
      "source": [
        "#@title\n",
        "model = CustomDebertaForClassification.from_pretrained(\n",
        "    \"microsoft/deberta-base\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing CustomDebertaForClassification: ['lm_predictions.lm_head.LayerNorm.bias', 'config', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n",
            "- This IS expected if you are initializing CustomDebertaForClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomDebertaForClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomDebertaForClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['encoder.layer.6.attention.self.pos_q_proj.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.pos_q_proj.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.5.attention.self.pos_proj.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.pos_q_proj.weight', 'encoder.layer.9.attention.self.q_bias', 'encoder.layer.8.attention.self.v_bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.attention.self.pos_proj.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.pos_proj.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.self.pos_q_proj.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.5.attention.self.q_bias', 'pooler.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.self.in_proj.weight', 'encoder.layer.0.attention.self.pos_q_proj.bias', 'encoder.layer.1.attention.self.pos_proj.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.attention.self.in_proj.weight', 'encoder.layer.3.attention.self.pos_proj.weight', 'encoder.layer.10.attention.self.v_bias', 'encoder.layer.11.attention.self.in_proj.weight', 'encoder.layer.3.attention.self.pos_q_proj.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.11.attention.self.q_bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.attention.self.pos_q_proj.bias', 'encoder.layer.8.attention.self.pos_proj.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.self.q_bias', 'encoder.layer.8.attention.self.pos_q_proj.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.pos_q_proj.weight', 'encoder.layer.8.attention.self.in_proj.weight', 'encoder.layer.0.attention.self.pos_q_proj.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.10.attention.self.pos_q_proj.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'classifier.bias', 'encoder.layer.5.attention.self.in_proj.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.in_proj.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.attention.self.q_bias', 'encoder.layer.5.attention.self.v_bias', 'embeddings.word_embeddings.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.self.q_bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.self.pos_q_proj.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.in_proj.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.v_bias', 'encoder.layer.8.attention.self.pos_q_proj.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.1.attention.self.pos_q_proj.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.in_proj.weight', 'encoder.layer.1.attention.self.q_bias', 'encoder.layer.10.attention.self.pos_q_proj.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.self.pos_q_proj.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.attention.self.v_bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.attention.self.pos_q_proj.weight', 'encoder.layer.0.attention.self.q_bias', 'encoder.layer.4.attention.self.q_bias', 'encoder.layer.4.attention.self.v_bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.attention.self.pos_proj.weight', 'encoder.layer.6.attention.self.v_bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.1.attention.self.v_bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.attention.self.pos_q_proj.bias', 'encoder.layer.7.attention.self.pos_proj.weight', 'classifier.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.pos_proj.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.attention.self.pos_q_proj.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.rel_embeddings.weight', 'encoder.layer.11.attention.self.pos_proj.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.attention.self.pos_proj.weight', 'encoder.layer.2.attention.self.pos_q_proj.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.attention.self.v_bias', 'encoder.layer.1.attention.self.in_proj.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.7.attention.self.in_proj.weight', 'encoder.layer.3.attention.self.v_bias', 'encoder.layer.6.attention.self.in_proj.weight', 'encoder.layer.7.attention.self.pos_q_proj.bias', 'encoder.layer.11.intermediate.dense.weight', 'pooler.dense.bias', 'encoder.layer.10.attention.self.in_proj.weight', 'encoder.layer.4.attention.self.pos_q_proj.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.pos_q_proj.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.self.pos_proj.weight', 'encoder.layer.11.attention.self.pos_q_proj.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.attention.self.v_bias', 'encoder.layer.10.attention.self.q_bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.3.attention.self.q_bias', 'encoder.layer.11.attention.self.v_bias', 'encoder.layer.2.attention.self.q_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomDebertaForClassification(\n",
              "  (deberta): DebertaModel(\n",
              "    (embeddings): DebertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "      (LayerNorm): DebertaLayerNorm()\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (1): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (2): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (3): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (4): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (5): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (6): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (7): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (8): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (9): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (10): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (11): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(1024, 768)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): StableDropout()\n",
              "  (embeddings): DebertaEmbeddings(\n",
              "    (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "    (LayerNorm): DebertaLayerNorm()\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (encoder): DebertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (1): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (2): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (3): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (4): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (5): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (6): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (7): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (8): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (9): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (10): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (11): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (rel_embeddings): Embedding(1024, 768)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmSpMRD5qaqE"
      },
      "source": [
        "##Noise Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG5DszcpDAjw"
      },
      "source": [
        "from torch.nn import LayerNorm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def normalize_embed(embed):\n",
        "    embed_mean = torch.mean(embed,dim=(1,2))\n",
        "    embed_std = torch.std(embed, dim=(1,2))\n",
        "\n",
        "    embed_clone = torch.clone(embed)\n",
        "\n",
        "    for i in range(0,embed_clone.size()[0]):\n",
        "        # embed_clone[i] = torch.div(torch.sub(embed_clone[i],embed_mean[i]),embed_std[i])\n",
        "        embed_clone[i] = (embed_clone[i] - embed_mean[i]) / embed_std[i]\n",
        "    return embed_clone, embed_mean, embed_std\n",
        "\n",
        "def denormalize_embed(embed, embed_mean, embed_std):\n",
        "    for i in range(0,embed.size()[0]):\n",
        "        # embed[i] = (embed[i] - embed_mean[i]) / embed_std[i]\n",
        "        embed[i] = (embed[i] * embed_std[i]) + embed_mean[i]\n",
        "    return embed \n",
        "\n",
        "def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n",
        "    logit = logit.view(-1, logit.size(-1)).float()\n",
        "    target = target.view(-1, target.size(-1)).float()\n",
        "    bs = logit.size(0)\n",
        "    p = F.log_softmax(logit, 1).exp()\n",
        "    y = F.log_softmax(target, 1).exp()\n",
        "    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n",
        "    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n",
        "    if reduce:\n",
        "        return (p* (rp- ry) * 2).sum() / bs\n",
        "    else:\n",
        "        return (p* (rp- ry) * 2).sum()\n",
        "\n",
        "def _norm_grad(grad, epsilon = 1e-6, eff_grad=None, sentence_level=False):\n",
        "        if sentence_level:\n",
        "            direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + epsilon)\n",
        "        else:\n",
        "            direction = grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "            eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "        return direction, eff_direction\n",
        "\n",
        "def noise(embed, model, attention_mask, step_size, normalize=False, k=1, mean=0, std=0.01):\n",
        "    if normalize == True:\n",
        "        \n",
        "        # LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n",
        "        # normalized_embed = LNorm(embed)\n",
        "        normalized_embed, embed_mean, embed_std = normalize_embed(embed)\n",
        "        logits = model.predict(normalized_embed,attention_mask)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(normalized_embed.size()[0],normalized_embed.size()[1],normalized_embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        adv_logits = model.predict(noised_normalized_embeddings, attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        denormalize_noised_embed = denormalize_embed(noised_normalized_embeddings,embed_mean, embed_std) \n",
        "        return denormalize_noised_embed\n",
        "\n",
        "    else:\n",
        "        logits = model.predict(embed,attention_mask)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(embed.size()[0],embed.size()[1],embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_embeddings = embed+noise\n",
        "        adv_logits = model.predict(noised_embeddings, attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_embeddings = embed+noise\n",
        "        return noised_embeddings\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bunW4qF4qSyZ"
      },
      "source": [
        "## Optimizer, Scheduler, and Some Other Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "#@title\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "#@title\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 3\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                          num_warmup_steps = 0,\n",
        "                          num_training_steps = total_steps\n",
        "                        )"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "#@title\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjvBSBfHtBc"
      },
      "source": [
        "MODE = \"SMART-adv-only\""
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCSpuOXLqor-"
      },
      "source": [
        "##Training Loop with Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72befe43-17ea-47c1-cec2-d18ea305f108"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        embed = model.embed(input_ids = b_input_ids,mask = b_input_mask)\n",
        "        preds = model.predict(embedding_output = embed,attention_mask = b_input_mask)\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "        loss_list = [regular_loss]\n",
        "        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "          normalise = True if MODE == \"SIFT\" else False\n",
        "          noised_embeddings = noise(embed, model, b_input_mask, 1e-3, normalize=normalise, k=1)\n",
        "          adv_logits = model.predict(noised_embeddings, b_input_mask)\n",
        "\n",
        "          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "          loss_list.append(adv_loss)\n",
        "        loss = sum(loss_list)\n",
        "        # END MODEL\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    360.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    360.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    360.    Elapsed: 0:01:08.\n",
            "  Batch   160  of    360.    Elapsed: 0:01:30.\n",
            "  Batch   200  of    360.    Elapsed: 0:01:53.\n",
            "  Batch   240  of    360.    Elapsed: 0:02:16.\n",
            "  Batch   280  of    360.    Elapsed: 0:02:38.\n",
            "  Batch   320  of    360.    Elapsed: 0:03:01.\n",
            "\n",
            "  Average training loss: 0.59\n",
            "  Training epcoh took: 0:03:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.91\n",
            "  Validation Loss: 0.22\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    360.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    360.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    360.    Elapsed: 0:01:08.\n",
            "  Batch   160  of    360.    Elapsed: 0:01:30.\n",
            "  Batch   200  of    360.    Elapsed: 0:01:53.\n",
            "  Batch   240  of    360.    Elapsed: 0:02:15.\n",
            "  Batch   280  of    360.    Elapsed: 0:02:38.\n",
            "  Batch   320  of    360.    Elapsed: 0:03:00.\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epcoh took: 0:03:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "  Validation Loss: 0.21\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    360.    Elapsed: 0:00:23.\n",
            "  Batch    80  of    360.    Elapsed: 0:00:45.\n",
            "  Batch   120  of    360.    Elapsed: 0:01:08.\n",
            "  Batch   160  of    360.    Elapsed: 0:01:30.\n",
            "  Batch   200  of    360.    Elapsed: 0:01:53.\n",
            "  Batch   240  of    360.    Elapsed: 0:02:15.\n",
            "  Batch   280  of    360.    Elapsed: 0:02:38.\n",
            "  Batch   320  of    360.    Elapsed: 0:03:00.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epcoh took: 0:03:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:10:17 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "c0f9c29c-ac04-45fa-f493-5595ef8e6a94"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.59</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0:03:23</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.43</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0:03:23</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0:03:23</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.59         0.22           0.91       0:03:23         0:00:03\n",
              "2               0.43         0.21           0.93       0:03:23         0:00:03\n",
              "3               0.46         0.19           0.93       0:03:23         0:00:03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "e75a8141-f69e-4335-8000-02c42fbf2619"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "##Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ea6007-c6d8-4f35-96a1-59bea7641081"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = df_ori[2000:]\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.tweet.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,  \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   ) \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        " \n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 2,442\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "###Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a19988-b62c-410e-d319-26a7d7e5e561"
      },
      "source": [
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 2,442 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26e9c93c-e878-410c-e84d-a489d7c3b5e5"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 1269 of 2442 (51.97%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ff509f-1100-47f3-d4bf-55206ba52ce3"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "print(sum(flat_predictions == flat_true_labels)/len(flat_predictions))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9193284193284194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03n-Q5lipMan"
      },
      "source": [
        "## Test on UCI with/without Further Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMVge1-YOww5"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RxdwXhIpTAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ee4aef86-79a5-41e8-a263-c1a76dbb501d"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/amazon_cells_labelled.txt\"\n",
        "download = requests.get(url).content\n",
        "df_amazon = pd.read_csv(io.StringIO(download.decode('utf-8')),delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df_amazon.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  So there is no way for me to plug it in here i...      0\n",
              "1                        Good case, Excellent value.      1\n",
              "2                             Great for the jawbone.      1\n",
              "3  Tied to charger for conversations lasting more...      0\n",
              "4                                  The mic is great.      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7Zyw07QpwNN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4f5adbe8-0b5e-418e-965c-2f356219e199"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/yelp_labelled.txt\"\n",
        "download = requests.get(url).content\n",
        "df_yelp = pd.read_csv(io.StringIO(download.decode('utf-8')),delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df_yelp.head()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc8moBqOp2QL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "dfc900d3-460a-422b-fe85-157d2a54cb4d"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/imdb_labelled.txt\"\n",
        "download = requests.get(url).content\n",
        "df_imdb = pd.read_csv(io.StringIO(download.decode('utf-8')),delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df_imdb.head()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  A very, very, very slow-moving, aimless movie ...      0\n",
              "1  Not sure who was more lost - the flat characte...      0\n",
              "2  Attempting artiness with black & white and cle...      0\n",
              "3       Very little music or anything to speak of.        0\n",
              "4  The best scene in the movie was when Gerardo i...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO1_TVbfqH4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "61dd1403-036d-45d5-c30c-39ad05958550"
      },
      "source": [
        "uci = pd.concat([df_imdb, df_amazon, df_yelp], axis = 0, join = 'inner')\n",
        "uci = uci.sample(frac = 1).reset_index(drop = True)\n",
        "uci.head()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's close to my house, it's low-key, non-fanc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you stay in Vegas you must get breakfast he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clipping this to your belt will deffinitely ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This is the phone to get for 2005.... I just b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i felt insulted and disrespected, how could yo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  It's close to my house, it's low-key, non-fanc...      1\n",
              "1  If you stay in Vegas you must get breakfast he...      1\n",
              "2  clipping this to your belt will deffinitely ma...      1\n",
              "3  This is the phone to get for 2005.... I just b...      1\n",
              "4  i felt insulted and disrespected, how could yo...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RjAHhEqO1O7"
      },
      "source": [
        "### Further Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQFbHqwEF9IL"
      },
      "source": [
        "# uci_further = uci[:270]\n",
        "# uci_test = uci[270:]"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yhsX0zGGWA2"
      },
      "source": [
        "# optimizer = AdamW(model.parameters(),\n",
        "#                   lr = 2e-5,\n",
        "#                   eps = 1e-8 \n",
        "#                 )\n",
        "\n",
        "# from transformers import get_linear_schedule_with_warmup\n",
        "# epochs = 3\n",
        "# total_steps = len(train_dataloader) * epochs\n",
        "# scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "#                           num_warmup_steps = 0,\n",
        "#                           num_training_steps = total_steps\n",
        "#                         )\n",
        "\n",
        "\n",
        "# sentences = uci_further.Sentence.values\n",
        "# labels = uci_further.Label.values\n",
        "\n",
        "# input_ids = []\n",
        "# attention_masks = []\n",
        "# for sent in sentences:\n",
        "#     encoded_dict = tokenizer.encode_plus(\n",
        "#                         sent,\n",
        "#                         add_special_tokens = True,\n",
        "#                         max_length = 256,\n",
        "#                         pad_to_max_length = True,\n",
        "#                         return_attention_mask = True,\n",
        "#                         return_tensors = 'pt',\n",
        "#                    )    \n",
        "#     input_ids.append(encoded_dict['input_ids'])\n",
        "#     attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# input_ids = torch.cat(input_ids, dim=0)\n",
        "# attention_masks = torch.cat(attention_masks, dim=0)\n",
        "# labels = torch.tensor(labels)\n",
        "\n",
        "\n",
        "# from torch.utils.data import TensorDataset, random_split\n",
        "# dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "# train_size = int(0.9 * len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# print('{:>5,} training samples'.format(train_size))\n",
        "# print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "\n",
        "\n",
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# batch_size = 5\n",
        "\n",
        "# train_dataloader = DataLoader(\n",
        "#             train_dataset,\n",
        "#             sampler = RandomSampler(train_dataset),\n",
        "#             batch_size = batch_size\n",
        "#         )\n",
        "\n",
        "\n",
        "# validation_dataloader = DataLoader(\n",
        "#             val_dataset, \n",
        "#             sampler = SequentialSampler(val_dataset),\n",
        "#             batch_size = batch_size\n",
        "#         )\n",
        "\n",
        "\n",
        "\n",
        "# import random\n",
        "# import numpy as np\n",
        "\n",
        "# seed_val = 42\n",
        "\n",
        "# random.seed(seed_val)\n",
        "# np.random.seed(seed_val)\n",
        "# torch.manual_seed(seed_val)\n",
        "# torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# training_stats = []\n",
        "# total_t0 = time.time()\n",
        "\n",
        "# # For each epoch...\n",
        "# for epoch_i in range(0, epochs):\n",
        "    \n",
        "#     # ========================================\n",
        "#     #               Training\n",
        "#     # ========================================\n",
        "    \n",
        "#     # Perform one full pass over the training set.\n",
        "\n",
        "#     print(\"\")\n",
        "#     print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "#     print('Training...')\n",
        "\n",
        "#     # Measure how long the training epoch takes.\n",
        "#     t0 = time.time()\n",
        "#     total_train_loss = 0\n",
        "#     model.train()\n",
        "\n",
        "#     # For each batch of training data...\n",
        "#     for step, batch in enumerate(train_dataloader):\n",
        "#         # Progress update every 40 batches.\n",
        "#         if step % 40 == 0 and not step == 0:\n",
        "#             elapsed = format_time(time.time() - t0)\n",
        "#             print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "#         b_input_ids = batch[0].to(device)\n",
        "#         b_input_mask = batch[1].to(device)\n",
        "#         b_labels = batch[2].to(device)\n",
        "\n",
        "#         model.zero_grad()        \n",
        "\n",
        "#         embed = model.embed(input_ids = b_input_ids,mask = b_input_mask)\n",
        "#         preds = model.predict(embedding_output = embed,attention_mask = b_input_mask)\n",
        "#         loss_fct = CrossEntropyLoss()\n",
        "#         regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "#         loss_list = [regular_loss]\n",
        "#         if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "#           normalise = True if MODE == \"SIFT\" else False\n",
        "#           noised_embeddings = noise(embed, model, b_input_mask, 1e-3, normalize=normalise, k=1)\n",
        "#           adv_logits = model.predict(noised_embeddings, b_input_mask)\n",
        "\n",
        "#           adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "#           loss_list.append(adv_loss)\n",
        "#         loss = sum(loss_list)\n",
        "#         # END MODEL\n",
        "#         total_train_loss += loss.item()\n",
        "#         loss.backward()\n",
        "\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "#         optimizer.step()\n",
        "#         scheduler.step()\n",
        "\n",
        "#     avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "#     training_time = format_time(time.time() - t0)\n",
        "\n",
        "#     print(\"\")\n",
        "#     print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "#     print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "#     # ========================================\n",
        "#     #               Validation\n",
        "#     # ========================================\n",
        "#     # After the completion of each training epoch, measure our performance on\n",
        "#     # our validation set.\n",
        "\n",
        "#     print(\"\")\n",
        "#     print(\"Running Validation...\")\n",
        "\n",
        "#     t0 = time.time()\n",
        "#     model.eval()\n",
        "#     total_eval_accuracy = 0\n",
        "#     total_eval_loss = 0\n",
        "#     nb_eval_steps = 0\n",
        "\n",
        "#     # Evaluate data for one epoch\n",
        "#     for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "#         b_input_ids = batch[0].to(device)\n",
        "#         b_input_mask = batch[1].to(device)\n",
        "#         b_labels = batch[2].to(device)\n",
        "\n",
        "#         with torch.no_grad():        \n",
        "\n",
        "#             result = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "#                            attention_mask=b_input_mask,\n",
        "#                            labels=b_labels,\n",
        "#                            return_dict=True)\n",
        "\n",
        "\n",
        "#         loss = result.loss\n",
        "#         logits = result.logits\n",
        "\n",
        "#         total_eval_loss += loss.item()\n",
        "\n",
        "#         logits = logits.detach().cpu().numpy()\n",
        "#         label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "#         total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "#     avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "#     print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "#     avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "#     validation_time = format_time(time.time() - t0)\n",
        "#     print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "#     print(\"  Validation took: {:}\".format(validation_time))\n",
        "#     training_stats.append(\n",
        "#         {\n",
        "#             'epoch': epoch_i + 1,\n",
        "#             'Training Loss': avg_train_loss,\n",
        "#             'Valid. Loss': avg_val_loss,\n",
        "#             'Valid. Accur.': avg_val_accuracy,\n",
        "#             'Training Time': training_time,\n",
        "#             'Validation Time': validation_time\n",
        "#         }\n",
        "#     )\n",
        "\n",
        "# print(\"\")\n",
        "# print(\"Training complete!\")\n",
        "\n",
        "# print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgzBiz15Uy37"
      },
      "source": [
        "### Testing on The Remaining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_e6ugkbqq0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f668254-9a94-4f50-a8bd-ec1c1be4c0af"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(uci.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = uci.Sentence.values\n",
        "labels = uci.Label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,  \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   ) \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        " \n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 2,748\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwLgyw49q5W7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b950d9d-7576-4475-ec29-e7501d24d3be"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  #print(logits.sum())\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 2,748 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXkdm29TrB0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12864ba5-6364-4d69-948a-42880b05fff4"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "print(np.sum(flat_predictions == flat_true_labels) / len(flat_true_labels))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4861717612809316\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}