{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwitterUCI_Deberta_SiFT_10%.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jJKaoairpdRa",
        "EFSJzwI5pujc",
        "hmSpMRD5qaqE",
        "bunW4qF4qSyZ"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b969eb314d3c425483bfc672da2fe96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ee46ca9adfed4cc494370e76186eaaac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_44b4c233c27b44db9d2ecdf955d39010",
              "IPY_MODEL_471cc168e4bd4f4ba483325e92a4660d"
            ]
          }
        },
        "ee46ca9adfed4cc494370e76186eaaac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44b4c233c27b44db9d2ecdf955d39010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27f53efac8be4c759bae61b7c176cf44",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898825,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898825,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99b30869e70b422db38eca07929a0ac9"
          }
        },
        "471cc168e4bd4f4ba483325e92a4660d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d49443c04904345847195b1fb3064d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:02&lt;00:00, 309kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d177bbf69b544d5d99fe0e39025fce1b"
          }
        },
        "27f53efac8be4c759bae61b7c176cf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99b30869e70b422db38eca07929a0ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d49443c04904345847195b1fb3064d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d177bbf69b544d5d99fe0e39025fce1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1710b56acd4a4a14a7f282fe948f241f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff11c26c765949ca9f316e1a1b3eb7ff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aabdbc1df8b74d68ab4afe5bd36a5c8d",
              "IPY_MODEL_0b2201fd58e540c99b6db4f4ef87bd75"
            ]
          }
        },
        "ff11c26c765949ca9f316e1a1b3eb7ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aabdbc1df8b74d68ab4afe5bd36a5c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a787797e950418db6ff25cb39a80cbd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d3de89a51dd4e3f99d26e62cd938e34"
          }
        },
        "0b2201fd58e540c99b6db4f4ef87bd75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_316c1346c11d4d5389992c609c486053",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:01&lt;00:00, 247kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62cf59c949eb4015905889a50039e8f5"
          }
        },
        "6a787797e950418db6ff25cb39a80cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d3de89a51dd4e3f99d26e62cd938e34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "316c1346c11d4d5389992c609c486053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62cf59c949eb4015905889a50039e8f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2ae0212223c4050a26e29bbe04824c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_faec7c3c030d45cfbee86f323db648ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c44b2746354463dbdb36553151e7c5d",
              "IPY_MODEL_9b0039d37b5c49c8830dc894b95c297c"
            ]
          }
        },
        "faec7c3c030d45cfbee86f323db648ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c44b2746354463dbdb36553151e7c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_615dd609dda745c9b2641875c8637bd9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 52,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 52,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e45e43999b1b4087a6dfc353202e7e43"
          }
        },
        "9b0039d37b5c49c8830dc894b95c297c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dcadab66ba4f4c46b4d1a360d1649440",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 52.0/52.0 [00:00&lt;00:00, 153B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6f9cc08a45f4431a0f2400c72901184"
          }
        },
        "615dd609dda745c9b2641875c8637bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e45e43999b1b4087a6dfc353202e7e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcadab66ba4f4c46b4d1a360d1649440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6f9cc08a45f4431a0f2400c72901184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2726ce37392a4d59853a3255ba0cd921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_975883f4829d4742bd2b6fdba0664081",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5448515968ff4209bb033bf1f258e737",
              "IPY_MODEL_00a677bdb7c94b4398db0c4302c9e9fe"
            ]
          }
        },
        "975883f4829d4742bd2b6fdba0664081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5448515968ff4209bb033bf1f258e737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e48727402a4e442cb6e4fcb5356e6fe8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 474,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 474,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6435d5df0258448a902054e9f96e85ae"
          }
        },
        "00a677bdb7c94b4398db0c4302c9e9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5e7861cb4e9412b89ee085d3f4dc71b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 474/474 [00:00&lt;00:00, 1.14kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cb61d1b56154129b3c2c9f8be2b8719"
          }
        },
        "e48727402a4e442cb6e4fcb5356e6fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6435d5df0258448a902054e9f96e85ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5e7861cb4e9412b89ee085d3f4dc71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cb61d1b56154129b3c2c9f8be2b8719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccd32a33b17b4e76823122f77d583fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b19d4af09084e5fb17524efa3629a00",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0932c03135b04adf9a8847e2f90e06ca",
              "IPY_MODEL_61a0388d473c4ce7a618c84d50ea4420"
            ]
          }
        },
        "2b19d4af09084e5fb17524efa3629a00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0932c03135b04adf9a8847e2f90e06ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0d9a5073bf9c467ab3b21298754de7c3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 558582766,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 558582766,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d552ccdfdbc483e861af30d908867b6"
          }
        },
        "61a0388d473c4ce7a618c84d50ea4420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6840a9d04bea4fd384db615c4bc2f05e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 559M/559M [00:28&lt;00:00, 19.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44b48202d4e6470cb58285810d438be4"
          }
        },
        "0d9a5073bf9c467ab3b21298754de7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d552ccdfdbc483e861af30d908867b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6840a9d04bea4fd384db615c4bc2f05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44b48202d4e6470cb58285810d438be4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# DeBERTa Fine-Tuning on CoLA with SMART and SiFT\n",
        "\n",
        "This notebook was orginally created by Chris McCormick and Nick Ryan. We made changes for SiFT and SMART, as well as our custom BERT/DeBERTa class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJKaoairpdRa"
      },
      "source": [
        "##Data and Importing Modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df213ee-5ca5-4394-e386-2b4f94cb82ac"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3a00560-293c-40c4-fca0-b7afb7c91c4e"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d54b144-8c66-45f8-fa65-3355e83d34de"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 15.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 55.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 49.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab763c81-71ea-41be-9e8e-0e3951090024"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=3c96290ba4ed22a4b1447a0edefef70de03c0619a05220ce61adb527ca465d8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "FBXpjYJ0iHcp",
        "outputId": "47fdbe17-129b-45bd-9057-84c697c31cde"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/fourth.csv\"\n",
        "download = requests.get(url).content\n",
        "df = pd.read_csv(io.StringIO(download.decode('utf-8')),index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    label                                              tweet\n",
              "id                                                          \n",
              "1       0   @user when a father is dysfunctional and is s...\n",
              "2       0  @user @user thanks for #lyft credit i can't us...\n",
              "3       0                                bihday your majesty\n",
              "4       0  #model   i love u take with u all the time in ...\n",
              "5       0             factsguide: society now    #motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5K7JlQ-BPts"
      },
      "source": [
        "df1 = df[df['label']==1]\n",
        "df0 = df[df['label']==0]\n",
        "df0 = df0[:2200]\n",
        "df_ori = pd.concat([df0, df1], axis = 0, join = 'inner')\n",
        "df_ori = df_ori.sample(frac = 1).reset_index(drop = True)\n",
        "df = df_ori[:2000]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "MvfL3MLjBsqb",
        "outputId": "d9104bba-cb28-4648-d0a6-7ae3a5eafdb4"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>'tis the season: #trump #newyork co-chair make...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>i'm just an ordinary girl #intruduceyourself  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>you might be a libtard if... #libtard  #sjw #l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>@user .@user what a douchebag. like his dad!  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>if #potus were white he'd still be the worst p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                              tweet\n",
              "0      1  'tis the season: #trump #newyork co-chair make...\n",
              "1      0  i'm just an ordinary girl #intruduceyourself  ...\n",
              "2      1  you might be a libtard if... #libtard  #sjw #l...\n",
              "3      1  @user .@user what a douchebag. like his dad!  ...\n",
              "4      1  if #potus were white he'd still be the worst p..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOPpgw4Gi6hc"
      },
      "source": [
        "sentences = df.tweet.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RAaRTCcDCOA",
        "outputId": "57d1db74-0257-4780-fd04-15a2796e1c94"
      },
      "source": [
        "labels.sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFSJzwI5pujc"
      },
      "source": [
        "## Tokenization and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "b969eb314d3c425483bfc672da2fe96f",
            "ee46ca9adfed4cc494370e76186eaaac",
            "44b4c233c27b44db9d2ecdf955d39010",
            "471cc168e4bd4f4ba483325e92a4660d",
            "27f53efac8be4c759bae61b7c176cf44",
            "99b30869e70b422db38eca07929a0ac9",
            "5d49443c04904345847195b1fb3064d3",
            "d177bbf69b544d5d99fe0e39025fce1b",
            "1710b56acd4a4a14a7f282fe948f241f",
            "ff11c26c765949ca9f316e1a1b3eb7ff",
            "aabdbc1df8b74d68ab4afe5bd36a5c8d",
            "0b2201fd58e540c99b6db4f4ef87bd75",
            "6a787797e950418db6ff25cb39a80cbd",
            "1d3de89a51dd4e3f99d26e62cd938e34",
            "316c1346c11d4d5389992c609c486053",
            "62cf59c949eb4015905889a50039e8f5",
            "b2ae0212223c4050a26e29bbe04824c9",
            "faec7c3c030d45cfbee86f323db648ad",
            "5c44b2746354463dbdb36553151e7c5d",
            "9b0039d37b5c49c8830dc894b95c297c",
            "615dd609dda745c9b2641875c8637bd9",
            "e45e43999b1b4087a6dfc353202e7e43",
            "dcadab66ba4f4c46b4d1a360d1649440",
            "a6f9cc08a45f4431a0f2400c72901184"
          ]
        },
        "outputId": "28198634-0662-42bf-c7f2-9ed87e7ce334"
      },
      "source": [
        "from transformers import DebertaTokenizer\n",
        "print('Loading DeBERTa tokenizer...')\n",
        "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading DeBERTa tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b969eb314d3c425483bfc672da2fe96f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898825.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1710b56acd4a4a14a7f282fe948f241f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2ae0212223c4050a26e29bbe04824c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=52.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2879bd5b-afd1-4b68-eeb7-d27b3195aea7"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  'tis the season: #trump #newyork co-chair makes  'gorilla' remark about #michelleobama - #carl #paladino  #disgraceful\n",
            "Tokenized:  [\"'t\", 'is', 'Ġthe', 'Ġseason', ':', 'Ġ#', 'trump', 'Ġ#', 'new', 'y', 'ork', 'Ġco', '-', 'chair', 'Ġmakes', 'Ġ', \"Ġ'\", 'gor', 'illa', \"'\", 'Ġremark', 'Ġabout', 'Ġ#', 'mic', 'helle', 'ob', 'ama', 'Ġ-', 'Ġ#', 'c', 'arl', 'Ġ#', 'pal', 'ad', 'ino', 'Ġ', 'Ġ#', 'dis', 'gr', 'ace', 'ful']\n",
            "Token IDs:  [75, 354, 5, 191, 35, 849, 38060, 849, 4651, 219, 9657, 1029, 12, 13599, 817, 1437, 128, 26084, 4699, 108, 17680, 59, 849, 15796, 28459, 2413, 2583, 111, 849, 438, 11278, 849, 18239, 625, 1696, 1437, 849, 7779, 6504, 4450, 2650]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1dd755e-dcbb-4cb0-d555-552a5bc08a08"
      },
      "source": [
        "max_len = 0\n",
        "for sent in sentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1b300b-aaaf-4d41-d876-c34bc3ee8e59"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  'tis the season: #trump #newyork co-chair makes  'gorilla' remark about #michelleobama - #carl #paladino  #disgraceful\n",
            "Token IDs: tensor([    1,    75,   354,     5,   191,    35,   849, 38060,   849,  4651,\n",
            "          219,  9657,  1029,    12, 13599,   817,  1437,   128, 26084,  4699,\n",
            "          108, 17680,    59,   849, 15796, 28459,  2413,  2583,   111,   849,\n",
            "          438, 11278,   849, 18239,   625,  1696,  1437,   849,  7779,  6504,\n",
            "         4450,  2650,     2,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598d2f80-2c52-4ad7-ffd3-8a9992d0db74"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,800 training samples\n",
            "  200 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73S4P4SMp6hX"
      },
      "source": [
        "## Custom Deberta Class and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOteWAT-Adqx"
      },
      "source": [
        "from transformers import DebertaForSequenceClassification, AdamW, DebertaConfig, DebertaPreTrainedModel, DebertaModel\n",
        "from transformers.models.deberta.modeling_deberta import *\n",
        "#from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "class CustomDebertaForClassification(DebertaForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        #self.bert = BertForSequenceClassification(config).from_pretrained(\"bert-base-uncased\",num_labels = 2,output_attentions = False, output_hidden_states = False)\n",
        "        self.embeddings = self.deberta.embeddings\n",
        "        self.encoder = self.deberta.encoder\n",
        "        self.z_steps = 0 #copied from DebertaModel source code\n",
        "\n",
        "\n",
        "    def embed(self, input_ids=None, \n",
        "                    mask=None,\n",
        "                    token_type_ids=None, \n",
        "                    position_ids=None, \n",
        "                    inputs_embeds=None\n",
        "                    ):\n",
        "        # See: BERTModel.forward\n",
        "        return self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            mask=mask,\n",
        "            inputs_embeds=inputs_embeds\n",
        "        )\n",
        "    \n",
        "    def predict(self,embedding_output,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_extended_attention_mask=None,\n",
        "                past_key_values=None,\n",
        "                use_cache=None,\n",
        "                output_attentions=None,\n",
        "                output_hidden_states=None,\n",
        "                return_dict=True): \n",
        "        encoder_outputs = self.encoder(\n",
        "                                        embedding_output,\n",
        "                                        attention_mask,\n",
        "                                        output_hidden_states=True,\n",
        "                                        output_attentions=output_attentions,\n",
        "                                        return_dict=return_dict\n",
        "        )\n",
        "        encoded_layers = encoder_outputs[1]\n",
        "\n",
        "        if self.z_steps > 1:\n",
        "            hidden_states = encoded_layers[-2]\n",
        "            layers = [self.encoder.layer[-1] for _ in range(self.z_steps)]\n",
        "            query_states = encoded_layers[-1]\n",
        "            rel_embeddings = self.encoder.get_rel_embedding()\n",
        "            attention_mask = self.encoder.get_attention_mask(attention_mask)\n",
        "            rel_pos = self.encoder.get_rel_pos(embedding_output)\n",
        "            for layer in layers[1:]:\n",
        "                query_states = layer(\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    return_att=False,\n",
        "                    query_states=query_states,\n",
        "                    relative_pos=rel_pos,\n",
        "                    rel_embeddings=rel_embeddings,\n",
        "                )\n",
        "                encoded_layers.append(query_states)\n",
        "\n",
        "        sequence_output = encoded_layers[-1]\n",
        "\n",
        "        # if not return_dict:\n",
        "        #     return (sequence_output,) + encoder_outputs[(1 if output_hidden_states else 2) :]\n",
        "\n",
        "        outputs = BaseModelOutput(\n",
        "            last_hidden_state=sequence_output,\n",
        "            hidden_states=encoder_outputs.hidden_states if output_hidden_states else None,\n",
        "            attentions=encoder_outputs.attentions,\n",
        "        )\n",
        "\n",
        "        \n",
        "\n",
        "        pooled_output = self.pooler(outputs[0])\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        return logits\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "2726ce37392a4d59853a3255ba0cd921",
            "975883f4829d4742bd2b6fdba0664081",
            "5448515968ff4209bb033bf1f258e737",
            "00a677bdb7c94b4398db0c4302c9e9fe",
            "e48727402a4e442cb6e4fcb5356e6fe8",
            "6435d5df0258448a902054e9f96e85ae",
            "e5e7861cb4e9412b89ee085d3f4dc71b",
            "2cb61d1b56154129b3c2c9f8be2b8719",
            "ccd32a33b17b4e76823122f77d583fe5",
            "2b19d4af09084e5fb17524efa3629a00",
            "0932c03135b04adf9a8847e2f90e06ca",
            "61a0388d473c4ce7a618c84d50ea4420",
            "0d9a5073bf9c467ab3b21298754de7c3",
            "6d552ccdfdbc483e861af30d908867b6",
            "6840a9d04bea4fd384db615c4bc2f05e",
            "44b48202d4e6470cb58285810d438be4"
          ]
        },
        "id": "IdNBO5qk2-i_",
        "collapsed": true,
        "outputId": "b6235611-cd5e-4786-d006-ce56384c0e23"
      },
      "source": [
        "#@title\n",
        "model = CustomDebertaForClassification.from_pretrained(\n",
        "    \"microsoft/deberta-base\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2726ce37392a4d59853a3255ba0cd921",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=474.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccd32a33b17b4e76823122f77d583fe5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=558582766.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing CustomDebertaForClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'config', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing CustomDebertaForClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomDebertaForClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomDebertaForClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['encoder.layer.3.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.9.attention.self.in_proj.weight', 'encoder.layer.4.attention.self.q_bias', 'encoder.layer.3.attention.self.v_bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.pos_q_proj.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.self.pos_q_proj.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.1.attention.self.in_proj.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.pos_q_proj.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.in_proj.weight', 'pooler.dense.bias', 'encoder.layer.0.attention.self.in_proj.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.self.v_bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.attention.self.pos_q_proj.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.pos_proj.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.v_bias', 'encoder.layer.1.attention.self.v_bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.self.q_bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.11.attention.self.in_proj.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.attention.self.in_proj.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.attention.self.pos_q_proj.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.10.attention.self.pos_q_proj.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.v_bias', 'pooler.dense.weight', 'encoder.layer.1.attention.self.q_bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.8.attention.self.q_bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.attention.self.q_bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.attention.self.pos_proj.weight', 'encoder.layer.10.attention.self.pos_proj.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'classifier.weight', 'encoder.layer.2.attention.self.q_bias', 'encoder.layer.5.attention.self.pos_proj.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.6.attention.self.pos_q_proj.bias', 'encoder.layer.2.attention.self.pos_proj.weight', 'encoder.layer.11.attention.self.v_bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.q_bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.rel_embeddings.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.11.attention.self.pos_q_proj.bias', 'encoder.layer.10.attention.self.pos_q_proj.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.in_proj.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.self.pos_q_proj.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.attention.self.pos_q_proj.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.self.pos_q_proj.bias', 'encoder.layer.4.attention.self.pos_q_proj.weight', 'encoder.layer.0.attention.self.pos_proj.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.pos_q_proj.weight', 'encoder.layer.1.attention.self.pos_proj.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.in_proj.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.6.attention.self.pos_q_proj.weight', 'encoder.layer.7.attention.self.v_bias', 'embeddings.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.self.in_proj.weight', 'encoder.layer.6.attention.self.q_bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'classifier.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.8.attention.self.v_bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.self.pos_proj.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.2.attention.self.pos_q_proj.weight', 'encoder.layer.10.attention.self.q_bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.attention.self.in_proj.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.pos_proj.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.attention.self.pos_proj.weight', 'encoder.layer.9.attention.self.v_bias', 'encoder.layer.11.attention.self.pos_proj.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.v_bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.self.pos_q_proj.weight', 'encoder.layer.8.attention.self.in_proj.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.0.attention.self.pos_q_proj.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.attention.self.pos_q_proj.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.attention.self.pos_q_proj.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.attention.self.q_bias', 'encoder.layer.7.attention.self.pos_q_proj.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.pos_q_proj.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.6.attention.self.in_proj.weight', 'encoder.layer.11.attention.self.pos_q_proj.weight', 'encoder.layer.7.attention.self.q_bias', 'encoder.layer.5.attention.self.pos_q_proj.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.0.attention.self.q_bias', 'encoder.layer.10.attention.self.v_bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.attention.self.v_bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.attention.self.pos_proj.weight', 'encoder.layer.10.attention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomDebertaForClassification(\n",
              "  (deberta): DebertaModel(\n",
              "    (embeddings): DebertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "      (LayerNorm): DebertaLayerNorm()\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (1): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (2): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (3): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (4): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (5): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (6): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (7): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (8): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (9): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (10): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (11): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(1024, 768)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): StableDropout()\n",
              "  (embeddings): DebertaEmbeddings(\n",
              "    (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "    (LayerNorm): DebertaLayerNorm()\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (encoder): DebertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (1): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (2): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (3): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (4): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (5): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (6): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (7): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (8): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (9): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (10): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (11): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (rel_embeddings): Embedding(1024, 768)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmSpMRD5qaqE"
      },
      "source": [
        "##Noise Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG5DszcpDAjw"
      },
      "source": [
        "from torch.nn import LayerNorm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def normalize_embed(embed):\n",
        "    embed_mean = torch.mean(embed,dim=(1,2))\n",
        "    embed_std = torch.std(embed, dim=(1,2))\n",
        "\n",
        "    embed_clone = torch.clone(embed)\n",
        "\n",
        "    for i in range(0,embed_clone.size()[0]):\n",
        "        # embed_clone[i] = torch.div(torch.sub(embed_clone[i],embed_mean[i]),embed_std[i])\n",
        "        embed_clone[i] = (embed_clone[i] - embed_mean[i]) / embed_std[i]\n",
        "    return embed_clone, embed_mean, embed_std\n",
        "\n",
        "def denormalize_embed(embed, embed_mean, embed_std):\n",
        "    for i in range(0,embed.size()[0]):\n",
        "        # embed[i] = (embed[i] - embed_mean[i]) / embed_std[i]\n",
        "        embed[i] = (embed[i] * embed_std[i]) + embed_mean[i]\n",
        "    return embed \n",
        "\n",
        "def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n",
        "    logit = logit.view(-1, logit.size(-1)).float()\n",
        "    target = target.view(-1, target.size(-1)).float()\n",
        "    bs = logit.size(0)\n",
        "    p = F.log_softmax(logit, 1).exp()\n",
        "    y = F.log_softmax(target, 1).exp()\n",
        "    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n",
        "    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n",
        "    if reduce:\n",
        "        return (p* (rp- ry) * 2).sum() / bs\n",
        "    else:\n",
        "        return (p* (rp- ry) * 2).sum()\n",
        "\n",
        "def _norm_grad(grad, epsilon = 1e-6, eff_grad=None, sentence_level=False):\n",
        "        if sentence_level:\n",
        "            direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + epsilon)\n",
        "        else:\n",
        "            direction = grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "            eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "        return direction, eff_direction\n",
        "\n",
        "def noise(embed, model, attention_mask, step_size, normalize=False, k=1, mean=0, std=0.01):\n",
        "    if normalize == True:\n",
        "        \n",
        "        # LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n",
        "        # normalized_embed = LNorm(embed)\n",
        "        normalized_embed, embed_mean, embed_std = normalize_embed(embed)\n",
        "        logits = model.predict(normalized_embed,attention_mask)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(normalized_embed.size()[0],normalized_embed.size()[1],normalized_embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        adv_logits = model.predict(noised_normalized_embeddings, attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        denormalize_noised_embed = denormalize_embed(noised_normalized_embeddings,embed_mean, embed_std) \n",
        "        return denormalize_noised_embed\n",
        "\n",
        "    else:\n",
        "        logits = model.predict(embed,attention_mask)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(embed.size()[0],embed.size()[1],embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_embeddings = embed+noise\n",
        "        adv_logits = model.predict(noised_embeddings, attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_embeddings = embed+noise\n",
        "        return noised_embeddings\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bunW4qF4qSyZ"
      },
      "source": [
        "## Optimizer, Scheduler, and Some Other Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "#@title\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "#@title\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                          num_warmup_steps = 0,\n",
        "                          num_training_steps = total_steps\n",
        "                        )"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "#@title\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjvBSBfHtBc"
      },
      "source": [
        "MODE = \"SIFT\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCSpuOXLqor-"
      },
      "source": [
        "##Training Loop with Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9825e644-de40-4be6-9fc0-e9f076b696d7"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        embed = model.embed(input_ids = b_input_ids,mask = b_input_mask)\n",
        "        preds = model.predict(embedding_output = embed,attention_mask = b_input_mask)\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "        loss_list = [regular_loss]\n",
        "        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "          normalise = True if MODE == \"SIFT\" else False\n",
        "          noised_embeddings = noise(embed, model, b_input_mask, 1e-3, normalize=normalise, k=1)\n",
        "          adv_logits = model.predict(noised_embeddings, b_input_mask)\n",
        "\n",
        "          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "          loss_list.append(adv_loss)\n",
        "        loss = sum(loss_list)\n",
        "        # END MODEL\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of    360.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    360.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    360.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    360.    Elapsed: 0:00:49.\n",
            "  Batch   200  of    360.    Elapsed: 0:01:02.\n",
            "  Batch   240  of    360.    Elapsed: 0:01:14.\n",
            "  Batch   280  of    360.    Elapsed: 0:01:26.\n",
            "  Batch   320  of    360.    Elapsed: 0:01:38.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:01:51\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.91\n",
            "  Validation Loss: 0.29\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:01:52 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "a1f24649-3e5a-458d-8519-6f79f11c372b"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.52</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0:01:51</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.52         0.29           0.91       0:01:51         0:00:01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "f1e623d1-9886-4b3b-fbce-b7cb305d3be8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "##Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b628533-95d5-4ee5-f9c3-776ca335bfac"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = df_ori[2000:]\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.tweet.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,  \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   ) \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        " \n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 2,442\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "###Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd9267bf-4573-4864-e667-1c1214cd748b"
      },
      "source": [
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 2,442 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38843015-2e6e-4988-afbf-1b06d482017b"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 1233 of 2442 (50.49%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73aa47d-d2e8-4d3a-99fc-0304c1600de6"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "print(sum(flat_predictions == flat_true_labels)/len(flat_predictions))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8906633906633906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03n-Q5lipMan"
      },
      "source": [
        "## Test on UCI with/without Further Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMVge1-YOww5"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RxdwXhIpTAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "73e07dd1-0722-4dd8-9754-379329df1bfa"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/amazon_cells_labelled.txt\"\n",
        "download = requests.get(url).content\n",
        "df_amazon = pd.read_csv(io.StringIO(download.decode('utf-8')),delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df_amazon.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  So there is no way for me to plug it in here i...      0\n",
              "1                        Good case, Excellent value.      1\n",
              "2                             Great for the jawbone.      1\n",
              "3  Tied to charger for conversations lasting more...      0\n",
              "4                                  The mic is great.      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7Zyw07QpwNN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "bbc4e285-1217-4db5-b01d-14b197c1964a"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/yelp_labelled.txt\"\n",
        "download = requests.get(url).content\n",
        "df_yelp = pd.read_csv(io.StringIO(download.decode('utf-8')),delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df_yelp.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc8moBqOp2QL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "e56afa1b-9c5a-4814-b55f-9b8525a938ac"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/wangluheng328/SiFT-Project/main/Data/imdb_labelled.txt\"\n",
        "download = requests.get(url).content\n",
        "df_imdb = pd.read_csv(io.StringIO(download.decode('utf-8')),delimiter = '\\t', delim_whitespace= False, names = ('Sentence', 'Label'))\n",
        "df_imdb.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  A very, very, very slow-moving, aimless movie ...      0\n",
              "1  Not sure who was more lost - the flat characte...      0\n",
              "2  Attempting artiness with black & white and cle...      0\n",
              "3       Very little music or anything to speak of.        0\n",
              "4  The best scene in the movie was when Gerardo i...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO1_TVbfqH4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "6972df43-4083-4bcc-8adb-4d481ec8f4ae"
      },
      "source": [
        "uci = pd.concat([df_imdb, df_amazon, df_yelp], axis = 0, join = 'inner')\n",
        "uci = uci.sample(frac = 1).reset_index(drop = True)\n",
        "uci.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's close to my house, it's low-key, non-fanc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you stay in Vegas you must get breakfast he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clipping this to your belt will deffinitely ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This is the phone to get for 2005.... I just b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i felt insulted and disrespected, how could yo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  It's close to my house, it's low-key, non-fanc...      1\n",
              "1  If you stay in Vegas you must get breakfast he...      1\n",
              "2  clipping this to your belt will deffinitely ma...      1\n",
              "3  This is the phone to get for 2005.... I just b...      1\n",
              "4  i felt insulted and disrespected, how could yo...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RjAHhEqO1O7"
      },
      "source": [
        "### Further Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQFbHqwEF9IL"
      },
      "source": [
        "uci_further = uci[:270]\n",
        "uci_test = uci[270:]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yhsX0zGGWA2",
        "outputId": "80ff4b7c-5d70-47ad-8ab7-662ae0d2235c"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 \n",
        "                )\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 3\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                          num_warmup_steps = 0,\n",
        "                          num_training_steps = total_steps\n",
        "                        )\n",
        "\n",
        "\n",
        "sentences = uci_further.Sentence.values\n",
        "labels = uci_further.Label.values\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        embed = model.embed(input_ids = b_input_ids,mask = b_input_mask)\n",
        "        preds = model.predict(embedding_output = embed,attention_mask = b_input_mask)\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "        loss_list = [regular_loss]\n",
        "        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "          normalise = True if MODE == \"SIFT\" else False\n",
        "          noised_embeddings = noise(embed, model, b_input_mask, 1e-3, normalize=normalise, k=1)\n",
        "          adv_logits = model.predict(noised_embeddings, b_input_mask)\n",
        "\n",
        "          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "          loss_list.append(adv_loss)\n",
        "        loss = sum(loss_list)\n",
        "        # END MODEL\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  243 training samples\n",
            "   27 validation samples\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of     49.    Elapsed: 0:00:12.\n",
            "\n",
            "  Average training loss: 0.77\n",
            "  Training epcoh took: 0:00:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.56\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of     49.    Elapsed: 0:00:12.\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Training epcoh took: 0:00:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "  Validation Loss: 0.09\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of     49.    Elapsed: 0:00:12.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epcoh took: 0:00:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.07\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:00:45 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgzBiz15Uy37"
      },
      "source": [
        "### Testing on The Remaining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_e6ugkbqq0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c9450cb-a82e-4d8e-c27e-7e8289d6b47b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(uci_test.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = uci_test.Sentence.values\n",
        "labels = uci_test.Label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 256,  \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   ) \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        " \n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 2,478\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwLgyw49q5W7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aedd5707-3fa7-4da2-8725-0564b4b3dfc5"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  #print(logits.sum())\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 2,478 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXkdm29TrB0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4bbab29-c054-4287-ef19-518484ab30a4"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "print(np.sum(flat_predictions == flat_true_labels) / len(flat_true_labels))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.910411622276029\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}