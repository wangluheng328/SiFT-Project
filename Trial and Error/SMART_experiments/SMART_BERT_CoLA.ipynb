{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52f771efffa94e6399d7b958951c5eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65394ce462e64eae895193af97d84d3b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5433d86629b6412fbd308d4e8f9f3de2",
              "IPY_MODEL_ed0497def0c8401e91e58d8d9a056dba"
            ]
          }
        },
        "65394ce462e64eae895193af97d84d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5433d86629b6412fbd308d4e8f9f3de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35bddb6b76014d38aa45b2a3c9e38af5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78fde5b243ab457eb948168f1f97c03a"
          }
        },
        "ed0497def0c8401e91e58d8d9a056dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_584f868ea410459bab38ba2ed63a70b3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 732kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54e77f4c6a354915b7fd24d7a257f054"
          }
        },
        "35bddb6b76014d38aa45b2a3c9e38af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78fde5b243ab457eb948168f1f97c03a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "584f868ea410459bab38ba2ed63a70b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54e77f4c6a354915b7fd24d7a257f054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab131265c0a34ddaa56fd4250292597a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4dfd2011e2f540c7a951d0577d6e6d22",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e5a1cc256c14b09ae72e03c560375fd",
              "IPY_MODEL_75bb387f820e4627a1883de7b1d8a0eb"
            ]
          }
        },
        "4dfd2011e2f540c7a951d0577d6e6d22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e5a1cc256c14b09ae72e03c560375fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4a185a1ce4c486ea0c3edf8590ea0e8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c7a3b2cc7e24d65b3c2de7cb8d19661"
          }
        },
        "75bb387f820e4627a1883de7b1d8a0eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e976a2fea6814f08b6b21572b5a67c01",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 147B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad56d3362f03467fb18a43c5df79084c"
          }
        },
        "f4a185a1ce4c486ea0c3edf8590ea0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c7a3b2cc7e24d65b3c2de7cb8d19661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e976a2fea6814f08b6b21572b5a67c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad56d3362f03467fb18a43c5df79084c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "045a9a00f1ad4c229fd21ece05d08b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dd278b8613064aa69b25c766c15e12ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_98db6324a2184af393c51bc1aa62f92c",
              "IPY_MODEL_5d2d2921d9914986a5a95805d22e05b2"
            ]
          }
        },
        "dd278b8613064aa69b25c766c15e12ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98db6324a2184af393c51bc1aa62f92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_334c8bec7f37408f886e1cd36961ed15",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0160d767cd9f483b89e38b8e6e1c252c"
          }
        },
        "5d2d2921d9914986a5a95805d22e05b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_39f4d319633244fa86b8dc8ebb418a60",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 4.79MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd98478c3f504c28a3ec789981ed8689"
          }
        },
        "334c8bec7f37408f886e1cd36961ed15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0160d767cd9f483b89e38b8e6e1c252c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39f4d319633244fa86b8dc8ebb418a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd98478c3f504c28a3ec789981ed8689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4995c10e8f1b4a168dd1110722b2d303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_14ee2f62169d426aadd61d3fb9397677",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a4a56f7de2024cca916c157e80778c8e",
              "IPY_MODEL_650f443637a2498ea6f8cf894ffde52f"
            ]
          }
        },
        "14ee2f62169d426aadd61d3fb9397677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4a56f7de2024cca916c157e80778c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e167c12811041fa9861d2298fc1f87b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6eaaffdccde9475f86ce8f67b8f63d3f"
          }
        },
        "650f443637a2498ea6f8cf894ffde52f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_86f97f19d8d64876b9e726ea1dd2d389",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 7.80kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed1121c576784b1e859019784f868436"
          }
        },
        "7e167c12811041fa9861d2298fc1f87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6eaaffdccde9475f86ce8f67b8f63d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86f97f19d8d64876b9e726ea1dd2d389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed1121c576784b1e859019784f868436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd5f6a163dfd46b0868aefa82cd39568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c1d8185240544a5b92f975e6c91ddfc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb3cce2ec08644d9bb87c80ee61b391e",
              "IPY_MODEL_a57d888d2efa4de5ac09d8399baa8045"
            ]
          }
        },
        "1c1d8185240544a5b92f975e6c91ddfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb3cce2ec08644d9bb87c80ee61b391e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e2e4b30a2df4b0f92ef68ad6157c258",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0982d7db98e14d8a83ce9c78fba30d52"
          }
        },
        "a57d888d2efa4de5ac09d8399baa8045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e81268f4e68a4e7dbdfda22f520f6c9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 45.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09f0af101548417f80aacd355a70b549"
          }
        },
        "7e2e4b30a2df4b0f92ef68ad6157c258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0982d7db98e14d8a83ce9c78fba30d52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e81268f4e68a4e7dbdfda22f520f6c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09f0af101548417f80aacd355a70b549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Fine-Tuning Tutorial with PyTorch\n",
        "\n",
        "By Chris McCormick and Nick Ryan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525f7498-4aef-41d9-f78e-b3a0bfd60910"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e70b3d5-b3b1-47fd-a76c-ebb05d8c9d34"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc41d16-db33-40c3-f061-cc7010d9b05b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 28.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8820a0-96b4-48a2-cc4c-3c4b9f04a50e"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=73ae9de29e40f96a9f588f0bf8c7242bc8abc6459e212a0dc52a10d28c68c001\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMtmPMkBzrvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f719d2-5c2f-4e22-805b-4aa6dbcd0e1b"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yv-tNv20dnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a4f612-a2c3-4074-a501-8f9046dcfbe8"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "98f3a833-3d3c-4383-f162-95d3c89f9938"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7574</th>\n",
              "      <td>sks13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>That's the truth.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6091</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Martha often thinks Kim hates phonology.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3345</th>\n",
              "      <td>l-93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>To him presented itself a wonderful opportunity.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3702</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John put a book on the table.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2918</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Smith was annealing.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3357</th>\n",
              "      <td>l-93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>The motorist happened the accident.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7222</th>\n",
              "      <td>sks13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>What Henri wants is the book which is on the t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5099</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>That was why she looked so nice.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1800</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The socks are ready for you to go about beginn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8194</th>\n",
              "      <td>ad03</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>I sent she away.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "7574           sks13  ...                                  That's the truth.\n",
              "6091            c_13  ...           Martha often thinks Kim hates phonology.\n",
              "3345            l-93  ...   To him presented itself a wonderful opportunity.\n",
              "3702            ks08  ...                      John put a book on the table.\n",
              "2918            l-93  ...                               Smith was annealing.\n",
              "3357            l-93  ...                The motorist happened the accident.\n",
              "7222           sks13  ...  What Henri wants is the book which is on the t...\n",
              "5099            ks08  ...                   That was why she looked so nice.\n",
              "1800            r-67  ...  The socks are ready for you to go about beginn...\n",
              "8194            ad03  ...                                   I sent she away.\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blqIvQaQncdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2285a856-527a-48d7-e611-c38d58fb9bb3"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7685</th>\n",
              "      <td>John convinced the rice to be cooked by Bill.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6099</th>\n",
              "      <td>John thinks that left.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7234</th>\n",
              "      <td>It was John Bill that were waiting at the rest...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2819</th>\n",
              "      <td>The cloth swatted the fly.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3464</th>\n",
              "      <td>much armchair is needed.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "7685      John convinced the rice to be cooked by Bill.      0\n",
              "6099                             John thinks that left.      0\n",
              "7234  It was John Bill that were waiting at the rest...      0\n",
              "2819                         The cloth swatted the fly.      0\n",
              "3464                           much armchair is needed.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "52f771efffa94e6399d7b958951c5eb4",
            "65394ce462e64eae895193af97d84d3b",
            "5433d86629b6412fbd308d4e8f9f3de2",
            "ed0497def0c8401e91e58d8d9a056dba",
            "35bddb6b76014d38aa45b2a3c9e38af5",
            "78fde5b243ab457eb948168f1f97c03a",
            "584f868ea410459bab38ba2ed63a70b3",
            "54e77f4c6a354915b7fd24d7a257f054",
            "ab131265c0a34ddaa56fd4250292597a",
            "4dfd2011e2f540c7a951d0577d6e6d22",
            "7e5a1cc256c14b09ae72e03c560375fd",
            "75bb387f820e4627a1883de7b1d8a0eb",
            "f4a185a1ce4c486ea0c3edf8590ea0e8",
            "4c7a3b2cc7e24d65b3c2de7cb8d19661",
            "e976a2fea6814f08b6b21572b5a67c01",
            "ad56d3362f03467fb18a43c5df79084c",
            "045a9a00f1ad4c229fd21ece05d08b27",
            "dd278b8613064aa69b25c766c15e12ed",
            "98db6324a2184af393c51bc1aa62f92c",
            "5d2d2921d9914986a5a95805d22e05b2",
            "334c8bec7f37408f886e1cd36961ed15",
            "0160d767cd9f483b89e38b8e6e1c252c",
            "39f4d319633244fa86b8dc8ebb418a60",
            "dd98478c3f504c28a3ec789981ed8689"
          ]
        },
        "outputId": "ae5251e2-9c78-4993-e50c-18833654c88a"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52f771efffa94e6399d7b958951c5eb4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab131265c0a34ddaa56fd4250292597a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "045a9a00f1ad4c229fd21ece05d08b27",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9444455a-474b-4054-9735-9b1ef4a0dbe8"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef4604b6-d1ee-42b4-8ad9-81510d8c1363"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8590d3-5ecc-4737-87ed-92d63b7732a4"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086c5608-79ad-4bed-fcd9-59280b7dc435"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7,695 training samples\n",
            "  856 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOteWAT-Adqx"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertPreTrainedModel, BertModel\n",
        "from transformers.models.bert.modeling_bert import BertEmbeddings,BertEncoder,BertPooler\n",
        "from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "class CustomBertForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        #self.bert = BertForSequenceClassification(config).from_pretrained(\"bert-base-uncased\",num_labels = 2,output_attentions = False, output_hidden_states = False)\n",
        "        self.embeddings = self.bert.embeddings\n",
        "        self.encoder = self.bert.encoder\n",
        "        self.pooler = self.bert.pooler\n",
        "\n",
        "    def embed(self, input_ids=None, \n",
        "                    token_type_ids=None, \n",
        "                    position_ids=None, \n",
        "                    inputs_embeds=None, \n",
        "                    past_key_values_length=0):\n",
        "        # See: BERTModel.forward \n",
        "        # ??? Some prep code\n",
        "        return self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            past_key_values_length=past_key_values_length\n",
        "        )\n",
        "    \n",
        "    def predict(self,embedding_output,\n",
        "                extended_attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_extended_attention_mask=None,\n",
        "                past_key_values=None,\n",
        "                use_cache=None,\n",
        "                output_attentions=None,\n",
        "                output_hidden_states=None,\n",
        "                return_dict=True):\n",
        "      # See: BERTModel.forward \n",
        "        encoder_outputs = self.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_extended_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
        "        \n",
        "        bert_output = BaseModelOutputWithPoolingAndCrossAttentions(\n",
        "                    last_hidden_state=sequence_output,\n",
        "                    pooler_output=pooled_output,\n",
        "                    past_key_values=encoder_outputs.past_key_values,\n",
        "                    hidden_states=encoder_outputs.hidden_states,\n",
        "                    attentions=encoder_outputs.attentions,\n",
        "                    cross_attentions=encoder_outputs.cross_attentions,\n",
        "                )\n",
        "\n",
        "        pooled_output = bert_output[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        return logits\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4995c10e8f1b4a168dd1110722b2d303",
            "14ee2f62169d426aadd61d3fb9397677",
            "a4a56f7de2024cca916c157e80778c8e",
            "650f443637a2498ea6f8cf894ffde52f",
            "7e167c12811041fa9861d2298fc1f87b",
            "6eaaffdccde9475f86ce8f67b8f63d3f",
            "86f97f19d8d64876b9e726ea1dd2d389",
            "ed1121c576784b1e859019784f868436",
            "dd5f6a163dfd46b0868aefa82cd39568",
            "1c1d8185240544a5b92f975e6c91ddfc",
            "fb3cce2ec08644d9bb87c80ee61b391e",
            "a57d888d2efa4de5ac09d8399baa8045",
            "7e2e4b30a2df4b0f92ef68ad6157c258",
            "0982d7db98e14d8a83ce9c78fba30d52",
            "e81268f4e68a4e7dbdfda22f520f6c9c",
            "09f0af101548417f80aacd355a70b549"
          ]
        },
        "id": "IdNBO5qk2-i_",
        "collapsed": true,
        "outputId": "a274dc89-3f21-47e6-8847-2582595ee44a"
      },
      "source": [
        "#@title\n",
        "model = CustomBertForClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4995c10e8f1b4a168dd1110722b2d303",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd5f6a163dfd46b0868aefa82cd39568",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing CustomBertForClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing CustomBertForClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomBertForClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomBertForClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomBertForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "#@title\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "#@title\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "#@title\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG5DszcpDAjw"
      },
      "source": [
        "from torch.nn import LayerNorm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n",
        "    logit = logit.view(-1, logit.size(-1)).float()\n",
        "    target = target.view(-1, target.size(-1)).float()\n",
        "    bs = logit.size(0)\n",
        "    p = F.log_softmax(logit, 1).exp()\n",
        "    y = F.log_softmax(target, 1).exp()\n",
        "    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n",
        "    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n",
        "    if reduce:\n",
        "        return (p* (rp- ry) * 2).sum() / bs\n",
        "    else:\n",
        "        return (p* (rp- ry) * 2).sum()\n",
        "\n",
        "def _norm_grad(grad, epsilon = 1e-6, eff_grad=None, sentence_level=False):\n",
        "        if sentence_level:\n",
        "            direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + epsilon)\n",
        "        else:\n",
        "            direction = grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "            eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "        return direction, eff_direction\n",
        "\n",
        "def noise(embed, model, step_size, normalize=False, k=1, mean=0, std=0.01):\n",
        "    if normalize == True:\n",
        "        logits = model.predict(embed)\n",
        "        \n",
        "        LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n",
        "        normalized_embed = LNorm(embed)\n",
        "        \n",
        "        noise = torch.normal(mean=0, std=0.01,size=(normalized_embed.size()[0],normalized_embed.size()[1],normalized_embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        adv_logits = model.predict(noised_normalized_embeddings)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        return noised_normalized_embeddings\n",
        "\n",
        "    else:\n",
        "        logits = model.predict(embed)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(embed.size()[0],embed.size()[1],embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_embeddings = embed+noise\n",
        "        adv_logits = model.predict(noised_embeddings)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_embeddings = embed+noise\n",
        "        return noised_embeddings\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjvBSBfHtBc"
      },
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "# from torch.nn import KLDivLoss\n",
        "MODE = \"SMART-adv-only\"\n",
        "\n",
        "# for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "#         # Progress update every 40 batches.\n",
        "#         if step  == 1:\n",
        "#             break\n",
        "\n",
        "#         b_input_ids = batch[0].to(device)\n",
        "#         b_input_mask = batch[1].to(device)\n",
        "#         b_labels = batch[2].to(device)\n",
        "\n",
        "      \n",
        "# embed = model.embed(input_ids = b_input_ids)\n",
        "# preds = model.predict(embedding_output = embed)\n",
        "# loss_fct = CrossEntropyLoss()\n",
        "# regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "# loss_list = [regular_loss]\n",
        "# if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "#         normalise = True if MODE == \"SIFT\" else False\n",
        "#         noised_embeddings = noise(embed, model, 1e-3, normalize=normalise, k=1)\n",
        "#         adv_logits = model.predict(embedding_output = noised_embeddings)\n",
        "\n",
        "#         adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "#         loss_list.append(adv_loss)\n",
        "# loss = sum(loss_list)\n",
        "# # END MODEL\n",
        "# loss.backward()\n",
        "# optimizer.step()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLFhvWR02Dyf"
      },
      "source": [
        "# embed.size()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ib-ViLMdQQz"
      },
      "source": [
        "# embed_mean = torch.mean(embed,dim=(1,2))\n",
        "# embed_std = torch.std(embed, dim=(1,2))\n",
        "# embed_norm = torch.norm(embed, dim=(1,2))\n",
        "# print(embed_mean)\n",
        "# print(embed_std)\n",
        "# print(embed_norm)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX3SEYF9cROa"
      },
      "source": [
        "# # normalized_embed = torch.nn.functional.normalize(embed)\n",
        "# LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n",
        "# normalized_embed = LNorm(embed)\n",
        "\n",
        "# normalized_embed_mean = torch.mean(normalized_embed,dim=(1,2))\n",
        "# normalized_embed_std = torch.std(normalized_embed, dim=(1,2))\n",
        "# normalized_embed_norm = torch.norm(normalized_embed, dim=(1,2))\n",
        "# print(normalized_embed_mean)\n",
        "# print(normalized_embed_std)\n",
        "# print(normalized_embed_norm)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF9PL0fVfvvf"
      },
      "source": [
        "# for i in range(0,embed.size()[0]):\n",
        "#     embed[0] = (embed[0] - embed_mean[0]) / embed_std[0]\n",
        "#     # embed[0] = embed[0] / embed_std[0]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb7aae1-a55c-4b4d-c52a-f10cb55601c8"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        embed = model.embed(input_ids = b_input_ids)\n",
        "        \n",
        "        preds = model.predict(embedding_output = embed)\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "        loss_list = [regular_loss]\n",
        "        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "          normalise = True if MODE == \"SIFT\" else False\n",
        "          noised_embeddings = noise(embed, model, 1e-3, normalize=normalise, k=1)\n",
        "          adv_logits = model.predict(embedding_output = noised_embeddings)\n",
        "\n",
        "          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "          loss_list.append(adv_loss)\n",
        "        loss = sum(loss_list)\n",
        "        # END MODEL\n",
        "        loss.backward()\n",
        "        \n",
        "        \n",
        "\n",
        "        # # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # # function and pass down the arguments. The `forward` function is \n",
        "        # # documented here: \n",
        "        # # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # # The results are returned in a results object, documented here:\n",
        "        # # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # # \"logits\"--the model outputs prior to activation.\n",
        "\n",
        "\n",
        "        # result = model(b_input_ids, \n",
        "        #                token_type_ids=None, \n",
        "        #                attention_mask=b_input_mask, \n",
        "        #                labels=b_labels,\n",
        "        #                return_dict=True)\n",
        "\n",
        "        # loss = result.loss\n",
        "        # logits = result.logits\n",
        "\n",
        "        # # Accumulate the training loss over all of the batches so that we can\n",
        "        # # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # # single value; the `.item()` function just returns the Python value \n",
        "        # # from the tensor.\n",
        "        # total_train_loss += loss.item()\n",
        "\n",
        "        # # Perform a backward pass to calculate the gradients.\n",
        "        # loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        " \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:36.\n",
            "  Batch    80  of    241.    Elapsed: 0:01:13.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:52.\n",
            "  Batch   160  of    241.    Elapsed: 0:02:32.\n",
            "  Batch   200  of    241.    Elapsed: 0:03:12.\n",
            "  Batch   240  of    241.    Elapsed: 0:03:53.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:03:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.56\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:41.\n",
            "  Batch    80  of    241.    Elapsed: 0:01:22.\n",
            "  Batch   120  of    241.    Elapsed: 0:02:03.\n",
            "  Batch   160  of    241.    Elapsed: 0:02:44.\n",
            "  Batch   200  of    241.    Elapsed: 0:03:25.\n",
            "  Batch   240  of    241.    Elapsed: 0:04:06.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:04:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.48\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:41.\n",
            "  Batch    80  of    241.    Elapsed: 0:01:22.\n",
            "  Batch   120  of    241.    Elapsed: 0:02:03.\n",
            "  Batch   160  of    241.    Elapsed: 0:02:44.\n",
            "  Batch   200  of    241.    Elapsed: 0:03:25.\n",
            "  Batch   240  of    241.    Elapsed: 0:04:06.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:04:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation Loss: 0.47\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:41.\n",
            "  Batch    80  of    241.    Elapsed: 0:01:22.\n",
            "  Batch   120  of    241.    Elapsed: 0:02:02.\n",
            "  Batch   160  of    241.    Elapsed: 0:02:43.\n",
            "  Batch   200  of    241.    Elapsed: 0:03:24.\n",
            "  Batch   240  of    241.    Elapsed: 0:04:05.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:04:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.46\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:16:25 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f4be334c-a21d-4edf-afdf-07a8030b8311"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0:03:54</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0:04:06</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:04:06</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0:04:05</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1                0.0         0.56           0.79       0:03:54         0:00:03\n",
              "2                0.0         0.48           0.80       0:04:06         0:00:04\n",
              "3                0.0         0.47           0.82       0:04:06         0:00:04\n",
              "4                0.0         0.46           0.81       0:04:05         0:00:04"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "Notice that, while the the training loss is going down with each epoch, the validation loss is increasing! This suggests that we are training our model too long, and it's over-fitting on the training data. \n",
        "\n",
        "(For reference, we are using 7,695 training samples and 856 validation samples).\n",
        "\n",
        "Validation Loss is a more precise measure than accuracy, because with accuracy we don't care about the exact output value, but just which side of a threshold it falls on. \n",
        "\n",
        "If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "24e4ba26-7db2-42b6-ae46-66bc4610a4f2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# 5. Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DosV94BYIYxg"
      },
      "source": [
        "Now we'll load the holdout dataset and prepare inputs just as we did with the training set. Then we'll evaluate predictions using [Matthew's correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) because this is the metric used by the wider NLP community to evaluate performance on CoLA. With this metric, +1 is the best score, and -1 is the worst score. This way, we can see how well we perform against the state of the art models for this specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### 5.1. Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee40f96-45a9-4783-ff63-c7b49071ab60"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "## 5.2. Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11dc756a-20ca-4e2c-9170-86b82f8761da"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jscIM8R4Gv"
      },
      "source": [
        "Accuracy on the CoLA benchmark is measured using the \"[Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\" (MCC).\n",
        "\n",
        "We use MCC here because the classes are imbalanced:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a005a54-69e0-4659-9c89-177d7db9a27a"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4fc5cc-e55f-454d-886d-b11fc855ab20"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUM0UA1qJaVB"
      },
      "source": [
        "The final score will be based on the entire test set, but let's take a look at the scores on the individual batches to get a sense of the variability in the metric between batches. \n",
        "\n",
        "Each batch has 32 sentences in it, except the last batch which has only (516 % 32) = 4 test sentences in it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyfY1tqxU0t9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "093ca2c0-ee2e-4863-927b-79c07e7afe55"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YrjAPX2V-l4"
      },
      "source": [
        "Now we'll combine the results for all of the batches and calculate our final MCC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af34fbea-310a-4121-a6fc-5a3d0a51d2a9"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXx0jPc4HUfZ"
      },
      "source": [
        "Cool! In about half an hour and without doing any hyperparameter tuning (adjusting the learning rate, epochs, batch size, ADAM properties, etc.) we are able to get a good score. \n",
        "\n",
        "> *Note: To maximize the score, we should remove the \"validation set\" (which we used to help determine how many epochs to train for) and train on the entire training set.*\n",
        "\n",
        "The library documents the expected accuracy for this benchmark [here](https://huggingface.co/transformers/examples.html#glue) as `49.23`.\n",
        "\n",
        "You can also look at the official leaderboard [here](https://gluebenchmark.com/leaderboard/submission/zlssuBTm5XRs0aSKbFYGVIVdvbj1/-LhijX9VVmvJcvzKymxy). \n",
        "\n",
        "Note that (due to the small dataset size?) the accuracy can vary significantly between runs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UktmHKRKMfCP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
