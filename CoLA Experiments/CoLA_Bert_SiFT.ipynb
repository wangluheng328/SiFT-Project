{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoLA_Bert_SiFT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Fine-Tuning on CoLA with SMART and SiFT\n",
        "\n",
        "This notebook was orginally created by Chris McCormick and Nick Ryan. We made changes for SiFT and SMART, as well as our custom BERT class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJKaoairpdRa"
      },
      "source": [
        "##Data and Importing Modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95025e37-0a2a-4715-da28-051d3daa0812"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3dab68-1cfe-4203-c778-4f72fb1b206b"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66f529a9-8b32-49bf-8e8d-5c28d1c27830"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7be8731-0c3e-4aa2-c2a2-c1b67d19a7b2"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMtmPMkBzrvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2889ce13-0702-4d01-e5eb-fd25c474aff7"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yv-tNv20dnH"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "63a50b05-8769-490b-8e65-f94b23ba8369"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2389</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Angela characterized Shelly as a lifesaver.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5048</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They're not finding it a stress being in the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3133</th>\n",
              "      <td>l-93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Paul exhaled on Mary.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5955</th>\n",
              "      <td>c_13</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>I ordered if John drink his beer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Press the stamp against the pad completely.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>They can very.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>m_02</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This arch is supporting the weight of the tower.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2908</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>That new handle detaches easily.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5857</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Brazilians pumped the oil across the river.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4191</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It is a wooden desk.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "2389            l-93  ...        Angela characterized Shelly as a lifesaver.\n",
              "5048            ks08  ...  They're not finding it a stress being in the s...\n",
              "3133            l-93  ...                              Paul exhaled on Mary.\n",
              "5955            c_13  ...                  I ordered if John drink his beer.\n",
              "625             bc01  ...        Press the stamp against the pad completely.\n",
              "3542            ks08  ...                                     They can very.\n",
              "6915            m_02  ...   This arch is supporting the weight of the tower.\n",
              "2908            l-93  ...                   That new handle detaches easily.\n",
              "5857            c_13  ...    The Brazilians pumped the oil across the river.\n",
              "4191            ks08  ...                               It is a wooden desk.\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blqIvQaQncdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "65dce6a0-b987-4bf1-cf65-5aae487f5f90"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6770</th>\n",
              "      <td>We realised that Dr Jones died because he ate ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1652</th>\n",
              "      <td>Here's a pole for you to kiss the girl who tie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>Jennifer baked at the potatoes.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4651</th>\n",
              "      <td>Kim is resembled by the model in nearly every ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2672</th>\n",
              "      <td>The book sent to Peter.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "6770  We realised that Dr Jones died because he ate ...      0\n",
              "1652  Here's a pole for you to kiss the girl who tie...      0\n",
              "3258                    Jennifer baked at the potatoes.      0\n",
              "4651  Kim is resembled by the model in nearly every ...      0\n",
              "2672                            The book sent to Peter.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFSJzwI5pujc"
      },
      "source": [
        "## Tokenization and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8535477f-8661-4f27-b800-0824695ea55b"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c7d6dd-da35-4aa1-b92d-938f8420074f"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39dd4975-f5d7-4c61-b144-58273d232c3e"
      },
      "source": [
        "max_len = 0\n",
        "for sent in sentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3ca24b-0c38-4060-8129-09078334c6b9"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43fa3012-a5ab-4800-8266-fbbbfe159ee5"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7,695 training samples\n",
            "  856 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73S4P4SMp6hX"
      },
      "source": [
        "## Custom Bert Class and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOteWAT-Adqx"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertPreTrainedModel, BertModel\n",
        "from transformers.models.bert.modeling_bert import BertEmbeddings,BertEncoder,BertPooler\n",
        "from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "class CustomBertForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        #self.bert = BertForSequenceClassification(config).from_pretrained(\"bert-base-uncased\",num_labels = 2,output_attentions = False, output_hidden_states = False)\n",
        "        self.embeddings = self.bert.embeddings\n",
        "        self.encoder = self.bert.encoder\n",
        "        self.pooler = self.bert.pooler\n",
        "\n",
        "    def embed(self, input_ids=None, \n",
        "                    token_type_ids=None, \n",
        "                    position_ids=None, \n",
        "                    inputs_embeds=None, \n",
        "                    past_key_values_length=0):\n",
        "        # See: BERTModel.forward\n",
        "        return self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            past_key_values_length=past_key_values_length\n",
        "        )\n",
        "    \n",
        "    def predict(self,embedding_output,\n",
        "                extended_attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_extended_attention_mask=None,\n",
        "                past_key_values=None,\n",
        "                use_cache=None,\n",
        "                output_attentions=None,\n",
        "                output_hidden_states=None,\n",
        "                return_dict=True):\n",
        "        encoder_outputs = self.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_extended_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
        "        \n",
        "        bert_output = BaseModelOutputWithPoolingAndCrossAttentions(\n",
        "                    last_hidden_state=sequence_output,\n",
        "                    pooler_output=pooled_output,\n",
        "                    past_key_values=encoder_outputs.past_key_values,\n",
        "                    hidden_states=encoder_outputs.hidden_states,\n",
        "                    attentions=encoder_outputs.attentions,\n",
        "                    cross_attentions=encoder_outputs.cross_attentions,\n",
        "                )\n",
        "\n",
        "        pooled_output = bert_output[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        return logits\n"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdNBO5qk2-i_",
        "collapsed": true,
        "outputId": "41a3cd0f-e55b-41d2-ea3e-2e6feac83aa8"
      },
      "source": [
        "#@title\n",
        "model = CustomBertForClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing CustomBertForClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing CustomBertForClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomBertForClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomBertForClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'classifier.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'pooler.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'classifier.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.self.value.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomBertForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmSpMRD5qaqE"
      },
      "source": [
        "##Noise Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG5DszcpDAjw"
      },
      "source": [
        "from torch.nn import LayerNorm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def normalize_embed(embed):\n",
        "    embed_mean = torch.mean(embed,dim=(1,2))\n",
        "    embed_std = torch.std(embed, dim=(1,2))\n",
        "\n",
        "    embed_clone = torch.clone(embed)\n",
        "\n",
        "    for i in range(0,embed_clone.size()[0]):\n",
        "        # embed_clone[i] = torch.div(torch.sub(embed_clone[i],embed_mean[i]),embed_std[i])\n",
        "        embed_clone[i] = (embed_clone[i] - embed_mean[i]) / embed_std[i]\n",
        "    return embed_clone, embed_mean, embed_std\n",
        "\n",
        "def denormalize_embed(embed, embed_mean, embed_std):\n",
        "    for i in range(0,embed.size()[0]):\n",
        "        # embed[i] = (embed[i] - embed_mean[i]) / embed_std[i]\n",
        "        embed[i] = (embed[i] * embed_std[i]) + embed_mean[i]\n",
        "    return embed \n",
        "\n",
        "def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n",
        "    logit = logit.view(-1, logit.size(-1)).float()\n",
        "    target = target.view(-1, target.size(-1)).float()\n",
        "    bs = logit.size(0)\n",
        "    p = F.log_softmax(logit, 1).exp()\n",
        "    y = F.log_softmax(target, 1).exp()\n",
        "    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n",
        "    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n",
        "    if reduce:\n",
        "        return (p* (rp- ry) * 2).sum() / bs\n",
        "    else:\n",
        "        return (p* (rp- ry) * 2).sum()\n",
        "\n",
        "def _norm_grad(grad, epsilon = 1e-6, eff_grad=None, sentence_level=False):\n",
        "        if sentence_level:\n",
        "            direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + epsilon)\n",
        "        else:\n",
        "            direction = grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "            eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "        return direction, eff_direction\n",
        "\n",
        "def noise(embed, model,step_size, normalize=False, k=1, mean=0, std=0.01):  ## Not including mask in the noise, so it means no mask as input for predict, should be a problem\n",
        "    if normalize == True:\n",
        "        logits = model.predict(embed)#,attention_mask)\n",
        "        # LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n",
        "        # normalized_embed = LNorm(embed)\n",
        "        normalized_embed, embed_mean, embed_std = normalize_embed(embed)\n",
        "\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(normalized_embed.size()[0],normalized_embed.size()[1],normalized_embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        adv_logits = model.predict(noised_normalized_embeddings)#,attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        denormalize_noised_embed = denormalize_embed(noised_normalized_embeddings,embed_mean, embed_std) \n",
        "        return denormalize_noised_embed\n",
        "    else:\n",
        "        logits = model.predict(embed)#,attention_mask)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(embed.size()[0],embed.size()[1],embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_embeddings = embed+noise\n",
        "        adv_logits = model.predict(noised_embeddings)#,attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_embeddings = embed+noise\n",
        "        return noised_embeddings\n",
        "\n"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bunW4qF4qSyZ"
      },
      "source": [
        "## Optimizer, Scheduler, and Some Other Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "#@title\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "#@title\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 6\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                          num_warmup_steps = 0,\n",
        "                          num_training_steps = total_steps\n",
        "                        )"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "#@title\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjvBSBfHtBc"
      },
      "source": [
        "MODE = \"SIFT\""
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCSpuOXLqor-"
      },
      "source": [
        "##Training Loop with Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d411c282-d084-4d69-ba0a-3a2c6d7964b1"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        embed = model.embed(input_ids = b_input_ids)\n",
        "        preds = model.predict(embedding_output = embed)#,extended_attention_mask=b_input_mask)   <- Didn't use mask at all, which should be a problem\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "        loss_list = [regular_loss]\n",
        "        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "          normalise = True if MODE == \"SIFT\" else False\n",
        "          noised_embeddings = noise(embed, model, 1e-3, normalize=normalise, k=1)\n",
        "          adv_logits = model.predict(embedding_output = noised_embeddings)#,extended_attention_mask = b_input_mask)   <- Didn't use mask at all, which should be a problem\n",
        "\n",
        "          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "          loss_list.append(adv_loss)\n",
        "        loss = sum(loss_list)\n",
        "        # END MODEL\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:04.\n",
            "\n",
            "  Average training loss: 0.62\n",
            "  Training epcoh took: 0:02:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.69\n",
            "  Validation Loss: 0.59\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:04.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:02:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 0.49\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:04.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 0:02:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.44\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:04.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:02:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 5 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:04.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epcoh took: 0:02:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.45\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 6 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:04.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epcoh took: 0:02:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.45\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:12:35 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "72c35af1-46ad-48af-e076-d909fc19cae8"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0:02:04</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0:02:04</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.48</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0:02:04</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.41</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0:02:04</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0:02:04</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0:02:04</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.62         0.59           0.69       0:02:04         0:00:02\n",
              "2               0.55         0.49           0.76       0:02:04         0:00:02\n",
              "3               0.48         0.44           0.80       0:02:04         0:00:02\n",
              "4               0.41         0.43           0.81       0:02:04         0:00:02\n",
              "5               0.37         0.45           0.80       0:02:04         0:00:02\n",
              "6               0.34         0.45           0.81       0:02:04         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "3919f28c-db80-43de-9d18-25bfbac74332"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "##Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "861db2c5-7711-4edb-f373-7bf9a4c1d1e1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,  \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   ) \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        " \n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "###Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f87c84d5-dcfe-451b-f097-9121599f8dfa"
      },
      "source": [
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jscIM8R4Gv"
      },
      "source": [
        "Accuracy on the CoLA benchmark is measured using the \"[Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\" (MCC).\n",
        "\n",
        "We use MCC here because the classes are imbalanced:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb79c984-0d09-46a8-9545-d0e13054b837"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0916d463-5e46-4426-af7e-f5277c0b3974"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyfY1tqxU0t9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "6551660b-3448-4fe7-8a68-c6dcc39d8a38"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YrjAPX2V-l4"
      },
      "source": [
        "Now we'll combine the results for all of the batches and calculate our final MCC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e4a4f1-827f-4406-fc66-2e2a0a3b06c8"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd-LgEsq6dBh"
      },
      "source": [
        ""
      ],
      "execution_count": 157,
      "outputs": []
    }
  ]
}