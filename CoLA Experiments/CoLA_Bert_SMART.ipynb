{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMART_CoLA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Fine-Tuning on CoLA with SMART and SiFT\n",
        "\n",
        "This notebook was orginally created by Chris McCormick and Nick Ryan. We made changes for SiFT and SMART, as well as our custom BERT class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJKaoairpdRa"
      },
      "source": [
        "##Data and Importing Modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fa0469a-3816-4892-c3dc-4438909928e8"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5337e22-974a-4f76-859d-e825b1a22ad4"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5188667b-2ef3-43d4-d294-0cce0178c71a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8818fc-e004-4a98-9046-4386ce4ce405"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMtmPMkBzrvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21cc37cc-597b-4f58-abf9-f6e9dcfe7067"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yv-tNv20dnH"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "259343e0-3678-40a0-a067-f2920f4c7024"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2389</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Angela characterized Shelly as a lifesaver.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5048</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They're not finding it a stress being in the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3133</th>\n",
              "      <td>l-93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Paul exhaled on Mary.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5955</th>\n",
              "      <td>c_13</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>I ordered if John drink his beer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Press the stamp against the pad completely.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>They can very.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>m_02</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This arch is supporting the weight of the tower.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2908</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>That new handle detaches easily.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5857</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Brazilians pumped the oil across the river.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4191</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It is a wooden desk.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "2389            l-93  ...        Angela characterized Shelly as a lifesaver.\n",
              "5048            ks08  ...  They're not finding it a stress being in the s...\n",
              "3133            l-93  ...                              Paul exhaled on Mary.\n",
              "5955            c_13  ...                  I ordered if John drink his beer.\n",
              "625             bc01  ...        Press the stamp against the pad completely.\n",
              "3542            ks08  ...                                     They can very.\n",
              "6915            m_02  ...   This arch is supporting the weight of the tower.\n",
              "2908            l-93  ...                   That new handle detaches easily.\n",
              "5857            c_13  ...    The Brazilians pumped the oil across the river.\n",
              "4191            ks08  ...                               It is a wooden desk.\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blqIvQaQncdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bd1dc4b3-3882-4ec7-ea8e-e58e8911dada"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6770</th>\n",
              "      <td>We realised that Dr Jones died because he ate ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1652</th>\n",
              "      <td>Here's a pole for you to kiss the girl who tie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>Jennifer baked at the potatoes.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4651</th>\n",
              "      <td>Kim is resembled by the model in nearly every ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2672</th>\n",
              "      <td>The book sent to Peter.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "6770  We realised that Dr Jones died because he ate ...      0\n",
              "1652  Here's a pole for you to kiss the girl who tie...      0\n",
              "3258                    Jennifer baked at the potatoes.      0\n",
              "4651  Kim is resembled by the model in nearly every ...      0\n",
              "2672                            The book sent to Peter.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFSJzwI5pujc"
      },
      "source": [
        "## Tokenization and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15e4490-ca40-48cc-9ca8-54c403bef45d"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec3ff0a-120a-438e-c5e5-3dec9e4cfaa1"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29876609-560a-4dd3-b2f6-a500783dd9b0"
      },
      "source": [
        "max_len = 0\n",
        "for sent in sentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbaffc93-1e1b-4da1-d829-c7b2386edbee"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6152cf22-3757-4bdf-c61f-ef64033e6beb"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7,695 training samples\n",
            "  856 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73S4P4SMp6hX"
      },
      "source": [
        "## Custom Bert Class and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOteWAT-Adqx"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertPreTrainedModel, BertModel\n",
        "from transformers.models.bert.modeling_bert import BertEmbeddings,BertEncoder,BertPooler\n",
        "from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "class CustomBertForClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        #self.bert = BertForSequenceClassification(config).from_pretrained(\"bert-base-uncased\",num_labels = 2,output_attentions = False, output_hidden_states = False)\n",
        "        self.embeddings = self.bert.embeddings\n",
        "        self.encoder = self.bert.encoder\n",
        "        self.pooler = self.bert.pooler\n",
        "\n",
        "    def embed(self, input_ids=None, \n",
        "                    token_type_ids=None, \n",
        "                    position_ids=None, \n",
        "                    inputs_embeds=None, \n",
        "                    past_key_values_length=0):\n",
        "        # See: BERTModel.forward\n",
        "        return self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            past_key_values_length=past_key_values_length\n",
        "        )\n",
        "    \n",
        "    def predict(self,embedding_output,\n",
        "                extended_attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_extended_attention_mask=None,\n",
        "                past_key_values=None,\n",
        "                use_cache=None,\n",
        "                output_attentions=None,\n",
        "                output_hidden_states=None,\n",
        "                return_dict=True):\n",
        "      # See: BERTModel.forward \n",
        "        encoder_outputs = self.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_extended_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
        "        \n",
        "        bert_output = BaseModelOutputWithPoolingAndCrossAttentions(\n",
        "                    last_hidden_state=sequence_output,\n",
        "                    pooler_output=pooled_output,\n",
        "                    past_key_values=encoder_outputs.past_key_values,\n",
        "                    hidden_states=encoder_outputs.hidden_states,\n",
        "                    attentions=encoder_outputs.attentions,\n",
        "                    cross_attentions=encoder_outputs.cross_attentions,\n",
        "                )\n",
        "\n",
        "        pooled_output = bert_output[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        return logits\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdNBO5qk2-i_",
        "collapsed": true,
        "outputId": "c69bad7b-18f5-4457-fb85-ced004fd75b0"
      },
      "source": [
        "#@title\n",
        "model = CustomBertForClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing CustomBertForClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing CustomBertForClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomBertForClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomBertForClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['embeddings.word_embeddings.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.output.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'classifier.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'classifier.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomBertForClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmSpMRD5qaqE"
      },
      "source": [
        "##Noise Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG5DszcpDAjw"
      },
      "source": [
        "from torch.nn import LayerNorm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def normalize_embed(embed):\n",
        "    embed_mean = torch.mean(embed,dim=(1,2))\n",
        "    embed_std = torch.std(embed, dim=(1,2))\n",
        "\n",
        "    embed_clone = torch.clone(embed)\n",
        "\n",
        "    for i in range(0,embed_clone.size()[0]):\n",
        "        # embed_clone[i] = torch.div(torch.sub(embed_clone[i],embed_mean[i]),embed_std[i])\n",
        "        embed_clone[i] = (embed_clone[i] - embed_mean[i]) / embed_std[i]\n",
        "    return embed_clone, embed_mean, embed_std\n",
        "\n",
        "def denormalize_embed(embed, embed_mean, embed_std):\n",
        "    for i in range(0,embed.size()[0]):\n",
        "        # embed[i] = (embed[i] - embed_mean[i]) / embed_std[i]\n",
        "        embed[i] = (embed[i] * embed_std[i]) + embed_mean[i]\n",
        "    return embed \n",
        "\n",
        "def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n",
        "    logit = logit.view(-1, logit.size(-1)).float()\n",
        "    target = target.view(-1, target.size(-1)).float()\n",
        "    bs = logit.size(0)\n",
        "    p = F.log_softmax(logit, 1).exp()\n",
        "    y = F.log_softmax(target, 1).exp()\n",
        "    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n",
        "    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n",
        "    if reduce:\n",
        "        return (p* (rp- ry) * 2).sum() / bs\n",
        "    else:\n",
        "        return (p* (rp- ry) * 2).sum()\n",
        "\n",
        "def _norm_grad(grad, epsilon = 1e-6, eff_grad=None, sentence_level=False):\n",
        "        if sentence_level:\n",
        "            direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + epsilon)\n",
        "        else:\n",
        "            direction = grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "            eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "        return direction, eff_direction\n",
        "\n",
        "def noise(embed, model, step_size, normalize=False, k=1, mean=0, std=0.01):\n",
        "    if normalize == True:\n",
        "        logits = model.predict(embed)\n",
        "        # LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n",
        "        # normalized_embed = LNorm(embed)\n",
        "        normalized_embed, embed_mean, embed_std = normalize_embed(embed)\n",
        "\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(normalized_embed.size()[0],normalized_embed.size()[1],normalized_embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        adv_logits = model.predict(noised_normalized_embeddings)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        denormalize_noised_embed = denormalize_embed(noised_normalized_embeddings,embed_mean, embed_std) \n",
        "        return denormalize_noised_embed\n",
        "    else:\n",
        "        logits = model.predict(embed)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(embed.size()[0],embed.size()[1],embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_embeddings = embed+noise\n",
        "        adv_logits = model.predict(noised_embeddings)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_embeddings = embed+noise\n",
        "        return noised_embeddings\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bunW4qF4qSyZ"
      },
      "source": [
        "## Optimizer, Scheduler, and Some Other Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "#@title\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "#@title\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 6\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                          num_warmup_steps = 0,\n",
        "                          num_training_steps = total_steps\n",
        "                        )"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "#@title\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjvBSBfHtBc"
      },
      "source": [
        "# MODE = \"SIFT\"\n",
        "MODE = \"SMART-adv-only\""
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCSpuOXLqor-"
      },
      "source": [
        "##Training Loop with Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42893bd4-7723-49c5-ec1f-17816ab7d3fa"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        embed = model.embed(input_ids = b_input_ids)\n",
        "        preds = model.predict(embedding_output = embed)\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "        loss_list = [regular_loss]\n",
        "        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "          normalise = True if MODE == \"SIFT\" else False\n",
        "          noised_embeddings = noise(embed, model, 1e-3, normalize=normalise, k=1)\n",
        "          adv_logits = model.predict(embedding_output = noised_embeddings)\n",
        "\n",
        "          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "          loss_list.append(adv_loss)\n",
        "        loss = sum(loss_list)\n",
        "        # END MODEL\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:01.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:21.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:42.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:02.\n",
            "\n",
            "  Average training loss: 0.63\n",
            "  Training epcoh took: 0:02:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 0.61\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:01.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:21.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:42.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:02.\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:02:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.55\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:01.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:22.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:42.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:03.\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:02:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.54\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:01.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:22.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:42.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:03.\n",
            "\n",
            "  Average training loss: 0.58\n",
            "  Training epcoh took: 0:02:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.57\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 5 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:01.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:22.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:42.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:03.\n",
            "\n",
            "  Average training loss: 0.56\n",
            "  Training epcoh took: 0:02:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.55\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 6 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:01.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:22.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:42.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:02.\n",
            "\n",
            "  Average training loss: 0.56\n",
            "  Training epcoh took: 0:02:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.55\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:12:26 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "5c44f500-bb7b-4f52-ddc5-bdb0af39a500"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.63</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0:02:02</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.61</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:02:02</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.61</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0:02:03</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.58</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0:02:03</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.56</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:02:03</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.56</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:02:03</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.63         0.61           0.76       0:02:02         0:00:02\n",
              "2               0.61         0.55           0.78       0:02:02         0:00:02\n",
              "3               0.61         0.54           0.81       0:02:03         0:00:02\n",
              "4               0.58         0.57           0.75       0:02:03         0:00:02\n",
              "5               0.56         0.55           0.78       0:02:03         0:00:02\n",
              "6               0.56         0.55           0.78       0:02:03         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "176e0d08-d38d-4b50-ba39-84c67ea8759e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "##Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c82f7ce-af7e-4416-b2bd-56cd533f6f3f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,  \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   ) \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        " \n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "###Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c9898a-439c-4557-c762-236c01018355"
      },
      "source": [
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jscIM8R4Gv"
      },
      "source": [
        "Accuracy on the CoLA benchmark is measured using the \"[Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\" (MCC).\n",
        "\n",
        "We use MCC here because the classes are imbalanced:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b54c8d-c4ad-4d96-991c-1b1a75464da8"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "060a81fa-a496-49ed-b1d9-a5b19ef6930c"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyfY1tqxU0t9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "f41773f7-f267-43c8-ff57-573e3ea7a6ba"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YrjAPX2V-l4"
      },
      "source": [
        "Now we'll combine the results for all of the batches and calculate our final MCC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b838249f-73ca-45fc-e0ca-79aeeb4e1208"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd-LgEsq6dBh"
      },
      "source": [
        ""
      ],
      "execution_count": 64,
      "outputs": []
    }
  ]
}