{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoLA_Deberta_SiFT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Fine-Tuning on CoLA with SMART and SiFT\n",
        "\n",
        "This notebook was orginally created by Chris McCormick and Nick Ryan. We made changes for SiFT and SMART, as well as our custom BERT class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJKaoairpdRa"
      },
      "source": [
        "##Data and Importing Modules "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ2Cn-7BXCOM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1600f77f-ba2e-4764-f8e3-a554c15e262e"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d4d6ad-a24a-40e1-f59b-a7d50d2b9b31"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5650480-cd03-45a4-f7b9-d14d4232dcd5"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa668976-e0f9-48d0-980a-2902657792bd"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMtmPMkBzrvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a189ada0-c3da-449f-8b88-b6baf14e5850"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yv-tNv20dnH"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "89ae77f4-1445-4767-c468-246175f29550"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2389</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Angela characterized Shelly as a lifesaver.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5048</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They're not finding it a stress being in the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3133</th>\n",
              "      <td>l-93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Paul exhaled on Mary.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5955</th>\n",
              "      <td>c_13</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>I ordered if John drink his beer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Press the stamp against the pad completely.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>They can very.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>m_02</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This arch is supporting the weight of the tower.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2908</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>That new handle detaches easily.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5857</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Brazilians pumped the oil across the river.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4191</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It is a wooden desk.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "2389            l-93  ...        Angela characterized Shelly as a lifesaver.\n",
              "5048            ks08  ...  They're not finding it a stress being in the s...\n",
              "3133            l-93  ...                              Paul exhaled on Mary.\n",
              "5955            c_13  ...                  I ordered if John drink his beer.\n",
              "625             bc01  ...        Press the stamp against the pad completely.\n",
              "3542            ks08  ...                                     They can very.\n",
              "6915            m_02  ...   This arch is supporting the weight of the tower.\n",
              "2908            l-93  ...                   That new handle detaches easily.\n",
              "5857            c_13  ...    The Brazilians pumped the oil across the river.\n",
              "4191            ks08  ...                               It is a wooden desk.\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blqIvQaQncdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2ae8af74-fd48-4f4f-ed34-a52b16411b2b"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6770</th>\n",
              "      <td>We realised that Dr Jones died because he ate ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1652</th>\n",
              "      <td>Here's a pole for you to kiss the girl who tie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>Jennifer baked at the potatoes.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4651</th>\n",
              "      <td>Kim is resembled by the model in nearly every ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2672</th>\n",
              "      <td>The book sent to Peter.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "6770  We realised that Dr Jones died because he ate ...      0\n",
              "1652  Here's a pole for you to kiss the girl who tie...      0\n",
              "3258                    Jennifer baked at the potatoes.      0\n",
              "4651  Kim is resembled by the model in nearly every ...      0\n",
              "2672                            The book sent to Peter.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFSJzwI5pujc"
      },
      "source": [
        "## Tokenization and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c18a90-1b63-4cc2-c90f-8dcb310d3316"
      },
      "source": [
        "from transformers import DebertaTokenizer\n",
        "print('Loading DeBERTa tokenizer...')\n",
        "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base', do_lower_case=True)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading DeBERTa tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9139de-cee1-4b31-d71d-c1e104b9fec8"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['Our', 'Ġfriends', 'Ġwon', \"'t\", 'Ġbuy', 'Ġthis', 'Ġanalysis', ',', 'Ġlet', 'Ġalone', 'Ġthe', 'Ġnext', 'Ġone', 'Ġwe', 'Ġpropose', '.']\n",
            "Token IDs:  [2522, 964, 351, 75, 907, 42, 1966, 6, 905, 1937, 5, 220, 65, 52, 15393, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165abb2b-78c2-4078-bfa4-e3cde0cc5ddd"
      },
      "source": [
        "max_len = 0\n",
        "for sent in sentences:\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d308602-4f74-4d8a-8a5c-4c580d67244e"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([    1,  2522,   964,   351,    75,   907,    42,  1966,     6,   905,\n",
            "         1937,     5,   220,    65,    52, 15393,     4,     2,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a579ea3b-08f3-4486-de19-4e511be2f8d2"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7,695 training samples\n",
            "  856 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73S4P4SMp6hX"
      },
      "source": [
        "## Custom Deberta Class and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOteWAT-Adqx"
      },
      "source": [
        "from transformers import DebertaForSequenceClassification, AdamW, DebertaConfig, DebertaPreTrainedModel, DebertaModel\n",
        "from transformers.models.deberta.modeling_deberta import *\n",
        "#from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "class CustomDebertaForClassification(DebertaForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        #self.bert = BertForSequenceClassification(config).from_pretrained(\"bert-base-uncased\",num_labels = 2,output_attentions = False, output_hidden_states = False)\n",
        "        self.embeddings = self.deberta.embeddings\n",
        "        self.encoder = self.deberta.encoder\n",
        "        self.z_steps = 0 #copied from DebertaModel source code\n",
        "\n",
        "\n",
        "    def embed(self, input_ids=None, \n",
        "                    mask=None,\n",
        "                    token_type_ids=None, \n",
        "                    position_ids=None, \n",
        "                    inputs_embeds=None\n",
        "                    ):\n",
        "        # See: BERTModel.forward\n",
        "        return self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            mask=mask,\n",
        "            inputs_embeds=inputs_embeds\n",
        "        )\n",
        "    \n",
        "    def predict(self,embedding_output,\n",
        "                attention_mask=None,\n",
        "                head_mask=None,\n",
        "                encoder_hidden_states=None,\n",
        "                encoder_extended_attention_mask=None,\n",
        "                past_key_values=None,\n",
        "                use_cache=None,\n",
        "                output_attentions=None,\n",
        "                output_hidden_states=None,\n",
        "                return_dict=True): \n",
        "        encoder_outputs = self.encoder(\n",
        "                                        embedding_output,\n",
        "                                        attention_mask,\n",
        "                                        output_hidden_states=True,\n",
        "                                        output_attentions=output_attentions,\n",
        "                                        return_dict=return_dict\n",
        "        )\n",
        "        encoded_layers = encoder_outputs[1]\n",
        "\n",
        "        if self.z_steps > 1:\n",
        "            hidden_states = encoded_layers[-2]\n",
        "            layers = [self.encoder.layer[-1] for _ in range(self.z_steps)]\n",
        "            query_states = encoded_layers[-1]\n",
        "            rel_embeddings = self.encoder.get_rel_embedding()\n",
        "            attention_mask = self.encoder.get_attention_mask(attention_mask)\n",
        "            rel_pos = self.encoder.get_rel_pos(embedding_output)\n",
        "            for layer in layers[1:]:\n",
        "                query_states = layer(\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    return_att=False,\n",
        "                    query_states=query_states,\n",
        "                    relative_pos=rel_pos,\n",
        "                    rel_embeddings=rel_embeddings,\n",
        "                )\n",
        "                encoded_layers.append(query_states)\n",
        "\n",
        "        sequence_output = encoded_layers[-1]\n",
        "\n",
        "        # if not return_dict:\n",
        "        #     return (sequence_output,) + encoder_outputs[(1 if output_hidden_states else 2) :]\n",
        "\n",
        "        outputs = BaseModelOutput(\n",
        "            last_hidden_state=sequence_output,\n",
        "            hidden_states=encoder_outputs.hidden_states if output_hidden_states else None,\n",
        "            attentions=encoder_outputs.attentions,\n",
        "        )\n",
        "\n",
        "        \n",
        "\n",
        "        pooled_output = self.pooler(outputs[0])\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        return logits\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdNBO5qk2-i_",
        "collapsed": true,
        "outputId": "999df7b7-fdb9-42a6-e734-08c7a3c17b8a"
      },
      "source": [
        "#@title\n",
        "model = CustomDebertaForClassification.from_pretrained(\n",
        "    \"microsoft/deberta-base\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing CustomDebertaForClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'config']\n",
            "- This IS expected if you are initializing CustomDebertaForClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomDebertaForClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomDebertaForClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.attention.self.pos_q_proj.bias', 'classifier.bias', 'encoder.layer.7.attention.self.v_bias', 'encoder.layer.3.attention.self.q_bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.attention.self.q_bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.attention.self.pos_q_proj.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.attention.self.in_proj.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.pos_q_proj.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.pos_proj.weight', 'encoder.layer.2.attention.self.pos_q_proj.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.attention.self.pos_q_proj.weight', 'encoder.layer.8.attention.output.dense.weight', 'pooler.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.7.attention.self.pos_proj.weight', 'encoder.layer.8.attention.self.pos_q_proj.weight', 'encoder.layer.1.attention.self.pos_q_proj.weight', 'encoder.layer.3.attention.self.pos_q_proj.weight', 'encoder.layer.10.attention.self.in_proj.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.3.attention.self.pos_q_proj.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.q_bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.self.in_proj.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.10.attention.self.pos_proj.weight', 'encoder.layer.1.attention.self.pos_proj.weight', 'encoder.layer.8.attention.self.pos_proj.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.11.attention.self.in_proj.weight', 'encoder.layer.6.attention.self.pos_q_proj.weight', 'encoder.layer.10.attention.self.v_bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.attention.self.in_proj.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.attention.self.pos_proj.weight', 'encoder.layer.2.attention.self.pos_proj.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.self.pos_q_proj.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.attention.self.q_bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.0.attention.self.pos_proj.weight', 'encoder.layer.10.attention.self.pos_q_proj.weight', 'encoder.layer.5.attention.self.v_bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.attention.self.pos_q_proj.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.2.attention.self.pos_q_proj.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.q_bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.pos_proj.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.6.attention.self.q_bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.attention.self.v_bias', 'encoder.layer.5.attention.self.pos_q_proj.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.self.v_bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.3.attention.self.in_proj.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.attention.self.pos_q_proj.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.attention.self.v_bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.5.attention.self.in_proj.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.6.attention.self.pos_proj.weight', 'encoder.layer.9.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.6.attention.self.in_proj.weight', 'encoder.layer.11.attention.self.pos_proj.weight', 'encoder.layer.0.attention.self.pos_q_proj.weight', 'encoder.layer.11.attention.self.v_bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.2.attention.self.q_bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.q_bias', 'encoder.layer.9.attention.self.pos_proj.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.v_bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.7.attention.self.q_bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.attention.self.pos_q_proj.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'classifier.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.2.attention.self.in_proj.weight', 'encoder.rel_embeddings.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.0.attention.self.in_proj.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.9.attention.self.pos_q_proj.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.attention.self.pos_q_proj.bias', 'encoder.layer.10.attention.self.q_bias', 'encoder.layer.0.attention.self.pos_q_proj.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.0.attention.self.v_bias', 'encoder.layer.6.attention.self.v_bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.pos_q_proj.bias', 'encoder.layer.1.attention.self.in_proj.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.4.attention.self.q_bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.attention.self.q_bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.pos_q_proj.bias', 'encoder.layer.7.attention.self.pos_q_proj.bias', 'encoder.layer.8.attention.self.v_bias', 'encoder.layer.4.attention.self.in_proj.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.4.attention.self.v_bias', 'encoder.layer.6.attention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomDebertaForClassification(\n",
              "  (deberta): DebertaModel(\n",
              "    (embeddings): DebertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "      (LayerNorm): DebertaLayerNorm()\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (1): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (2): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (3): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (4): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (5): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (6): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (7): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (8): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (9): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (10): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (11): DebertaLayer(\n",
              "          (attention): DebertaAttention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(1024, 768)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): StableDropout()\n",
              "  (embeddings): DebertaEmbeddings(\n",
              "    (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "    (LayerNorm): DebertaLayerNorm()\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (encoder): DebertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (1): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (2): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (3): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (4): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (5): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (6): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (7): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (8): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (9): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (10): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "      (11): DebertaLayer(\n",
              "        (attention): DebertaAttention(\n",
              "          (self): DisentangledSelfAttention(\n",
              "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "            (pos_dropout): StableDropout()\n",
              "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "          (output): DebertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): DebertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): DebertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): DebertaLayerNorm()\n",
              "          (dropout): StableDropout()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (rel_embeddings): Embedding(1024, 768)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmSpMRD5qaqE"
      },
      "source": [
        "##Noise Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG5DszcpDAjw"
      },
      "source": [
        "from torch.nn import LayerNorm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def normalize_embed(embed):\n",
        "    embed_mean = torch.mean(embed,dim=(1,2))\n",
        "    embed_std = torch.std(embed, dim=(1,2))\n",
        "\n",
        "    embed_clone = torch.clone(embed)\n",
        "\n",
        "    for i in range(0,embed_clone.size()[0]):\n",
        "        # embed_clone[i] = torch.div(torch.sub(embed_clone[i],embed_mean[i]),embed_std[i])\n",
        "        embed_clone[i] = (embed_clone[i] - embed_mean[i]) / embed_std[i]\n",
        "    return embed_clone, embed_mean, embed_std\n",
        "\n",
        "def denormalize_embed(embed, embed_mean, embed_std):\n",
        "    for i in range(0,embed.size()[0]):\n",
        "        # embed[i] = (embed[i] - embed_mean[i]) / embed_std[i]\n",
        "        embed[i] = (embed[i] * embed_std[i]) + embed_mean[i]\n",
        "    return embed \n",
        "\n",
        "def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n",
        "    logit = logit.view(-1, logit.size(-1)).float()\n",
        "    target = target.view(-1, target.size(-1)).float()\n",
        "    bs = logit.size(0)\n",
        "    p = F.log_softmax(logit, 1).exp()\n",
        "    y = F.log_softmax(target, 1).exp()\n",
        "    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n",
        "    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n",
        "    if reduce:\n",
        "        return (p* (rp- ry) * 2).sum() / bs\n",
        "    else:\n",
        "        return (p* (rp- ry) * 2).sum()\n",
        "\n",
        "def _norm_grad(grad, epsilon = 1e-6, eff_grad=None, sentence_level=False):\n",
        "        if sentence_level:\n",
        "            direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + epsilon)\n",
        "        else:\n",
        "            direction = grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "            eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + epsilon)\n",
        "        return direction, eff_direction\n",
        "\n",
        "def noise(embed, model, attention_mask, step_size, normalize=False, k=1, mean=0, std=0.01):\n",
        "    if normalize == True:\n",
        "        logits = model.predict(embed,attention_mask)\n",
        "        # LNorm = LayerNorm(embed.size(),elementwise_affine=False)\n",
        "        # normalized_embed = LNorm(embed)\n",
        "        normalized_embed, embed_mean, embed_std = normalize_embed(embed)\n",
        "\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(normalized_embed.size()[0],normalized_embed.size()[1],normalized_embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        adv_logits = model.predict(noised_normalized_embeddings, attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_normalized_embeddings = normalized_embed+noise\n",
        "        denormalize_noised_embed = denormalize_embed(noised_normalized_embeddings,embed_mean, embed_std) \n",
        "        return denormalize_noised_embed\n",
        "\n",
        "    else:\n",
        "        logits = model.predict(embed,attention_mask)\n",
        "        noise = torch.normal(mean=0, std=0.01,size=(embed.size()[0],embed.size()[1],embed.size()[2]))\n",
        "        noise = noise.to(device)\n",
        "        noise.requires_grad_()\n",
        "        noised_embeddings = embed+noise\n",
        "        adv_logits = model.predict(noised_embeddings, attention_mask)\n",
        "        adv_loss = stable_kl(adv_logits, logits.detach(), reduce=False)\n",
        "        delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
        "        norm = delta_grad.norm()\n",
        "        # if (torch.isnan(norm) or torch.isinf(norm)):\n",
        "        #     return 0\n",
        "        eff_delta_grad = delta_grad * step_size\n",
        "        delta_grad = noise + delta_grad * step_size\n",
        "        noise, eff_noise = _norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=0)\n",
        "        noise = noise.detach()\n",
        "        noised_embeddings = embed+noise\n",
        "        return noised_embeddings\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bunW4qF4qSyZ"
      },
      "source": [
        "## Optimizer, Scheduler, and Some Other Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "#@title\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "#@title\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 6\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                          num_warmup_steps = 0,\n",
        "                          num_training_steps = total_steps\n",
        "                        )"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "#@title\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjvBSBfHtBc"
      },
      "source": [
        "MODE = \"SIFT\""
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCSpuOXLqor-"
      },
      "source": [
        "##Training Loop with Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8c348f1-8a69-475f-b64c-ad856cd80f4b"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        embed = model.embed(input_ids = b_input_ids,mask = b_input_mask)\n",
        "        preds = model.predict(embedding_output = embed,attention_mask = b_input_mask)\n",
        "        loss_fct = CrossEntropyLoss()\n",
        "        regular_loss = loss_fct(preds.view(-1,2), b_labels.view(-1))\n",
        "        loss_list = [regular_loss]\n",
        "        if MODE in [\"SMART-adv-only\", \"SIFT\"]:\n",
        "          normalise = True if MODE == \"SIFT\" else False\n",
        "          noised_embeddings = noise(embed, model, b_input_mask, 1e-3, normalize=normalise, k=1)\n",
        "          adv_logits = model.predict(noised_embeddings, b_input_mask)\n",
        "\n",
        "          adv_loss = stable_kl(preds.view(-1,2), adv_logits.view(-1,2))\n",
        "          loss_list.append(adv_loss)\n",
        "        loss = sum(loss_list)\n",
        "        # END MODEL\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)   \n",
        "\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:52.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:18.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:44.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:10.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:36.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:02:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:52.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:18.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:44.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:10.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:36.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 0:02:36\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation Loss: 0.44\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:52.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:18.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:44.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:10.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:36.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:02:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation Loss: 0.42\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:52.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:18.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:44.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:10.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:36.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epcoh took: 0:02:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.46\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 5 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:52.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:18.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:44.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:10.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:36.\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epcoh took: 0:02:36\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 6 / 6 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:52.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:18.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:44.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:10.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:36.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epcoh took: 0:02:36\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:15:51 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "39690fab-2ccc-40ca-9af8-5e399a27e6e2"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0:02:37</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.48</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0:02:36</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.41</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:02:37</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0:02:37</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:02:36</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:02:36</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.57         0.43           0.81       0:02:37         0:00:02\n",
              "2               0.48         0.44           0.82       0:02:36         0:00:02\n",
              "3               0.41         0.42           0.83       0:02:37         0:00:02\n",
              "4               0.37         0.46           0.81       0:02:37         0:00:02\n",
              "5               0.33         0.43           0.84       0:02:36         0:00:02\n",
              "6               0.29         0.43           0.84       0:02:36         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "98337231-dc9f-4ced-fa1c-aede67f81885"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "##Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c168c710-93f6-4b9f-e595-2ae99f12f224"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent, \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,  \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True, \n",
        "                        return_tensors = 'pt',\n",
        "                   ) \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        " \n",
        "batch_size = 32  \n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "###Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4566fa86-f341-44fc-9949-9faeae9ad196"
      },
      "source": [
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jscIM8R4Gv"
      },
      "source": [
        "Accuracy on the CoLA benchmark is measured using the \"[Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\" (MCC).\n",
        "\n",
        "We use MCC here because the classes are imbalanced:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0296fe0-495f-45f1-92de-c49e116e759c"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a87bbef-0a5c-48a5-cdca-c6fb79d31531"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyfY1tqxU0t9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "a42e3c58-bb73-4c65-cf12-76426600ed23"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YrjAPX2V-l4"
      },
      "source": [
        "Now we'll combine the results for all of the batches and calculate our final MCC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9bee0f3-d23c-4dfe-fac8-2aa10866f252"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.572\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}